package falcon512

import (
	"unsafe"

	"github.com/gotranspile/cxgo/runtime/libc"
)

const DEPTH_INT_FG = 4

type small_prime struct {
	p uint32
	g uint32
	s uint32
}

var PRIMES [522]small_prime = [522]small_prime{{p: 2147473409, g: 383167813, s: 10239}, {p: 2147389441, g: 211808905, s: 471403745}, {p: 2147387393, g: 37672282, s: 1329335065}, {p: 2147377153, g: 1977035326, s: 968223422}, {p: 2147358721, g: 1067163706, s: 132460015}, {p: 2147352577, g: 1606082042, s: 598693809}, {p: 2147346433, g: 2033915641, s: 1056257184}, {p: 2147338241, g: 1653770625, s: 421286710}, {p: 2147309569, g: 631200819, s: 1111201074}, {p: 2147297281, g: 2038364663, s: 1042003613}, {p: 2147295233, g: 1962540515, s: 19440033}, {p: 2147239937, g: 2100082663, s: 353296760}, {p: 2147235841, g: 1991153006, s: 1703918027}, {p: 2147217409, g: 516405114, s: 1258919613}, {p: 2147205121, g: 409347988, s: 1089726929}, {p: 2147196929, g: 927788991, s: 1946238668}, {p: 2147178497, g: 1136922411, s: 1347028164}, {p: 2147100673, g: 868626236, s: 701164723}, {p: 2147082241, g: 1897279176, s: 617820870}, {p: 2147074049, g: 1888819123, s: 158382189}, {p: 2147051521, g: 25006327, s: 522758543}, {p: 2147043329, g: 327546255, s: 37227845}, {p: 2147039233, g: 766324424, s: 1133356428}, {p: 2146988033, g: 1862817362, s: 73861329}, {p: 2146963457, g: 404622040, s: 653019435}, {p: 2146959361, g: 1936581214, s: 995143093}, {p: 2146938881, g: 1559770096, s: 634921513}, {p: 2146908161, g: 422623708, s: 1985060172}, {p: 2146885633, g: 1751189170, s: 298238186}, {p: 2146871297, g: 578919515, s: 291810829}, {p: 2146846721, g: 1114060353, s: 915902322}, {p: 2146834433, g: 2069565474, s: 47859524}, {p: 2146818049, g: 1552824584, s: 646281055}, {p: 2146775041, g: 1906267847, s: 1597832891}, {p: 2146756609, g: 1847414714, s: 1228090888}, {p: 2146744321, g: 1818792070, s: 1176377637}, {p: 2146738177, g: 1118066398, s: 1054971214}, {p: 2146736129, g: 52057278, s: 933422153}, {p: 2146713601, g: 592259376, s: 1406621510}, {p: 2146695169, g: 263161877, s: 1514178701}, {p: 2146656257, g: 685363115, s: 384505091}, {p: 2146650113, g: 927727032, s: 537575289}, {p: 2146646017, g: 52575506, s: 1799464037}, {p: 2146643969, g: 1276803876, s: 1348954416}, {p: 2146603009, g: 814028633, s: 1521547704}, {p: 2146572289, g: 1846678872, s: 1310832121}, {p: 2146547713, g: 919368090, s: 1019041349}, {p: 2146508801, g: 671847612, s: 38582496}, {p: 2146492417, g: 283911680, s: 532424562}, {p: 2146490369, g: 1780044827, s: 896447978}, {p: 2146459649, g: 327980850, s: 1327906900}, {p: 2146447361, g: 1310561493, s: 958645253}, {p: 2146441217, g: 412148926, s: 287271128}, {p: 2146437121, g: 293186449, s: 2009822534}, {p: 2146430977, g: 179034356, s: 1359155584}, {p: 2146418689, g: 1517345488, s: 1790248672}, {p: 2146406401, g: 1615820390, s: 1584833571}, {p: 2146404353, g: 826651445, s: 607120498}, {p: 2146379777, g: 3816988, s: 1897049071}, {p: 2146363393, g: 1221409784, s: 1986921567}, {p: 2146355201, g: 1388081168, s: 849968120}, {p: 2146336769, g: 1803473237, s: 1655544036}, {p: 2146312193, g: 1023484977, s: 273671831}, {p: 2146293761, g: 1074591448, s: 467406983}, {p: 2146283521, g: 831604668, s: 1523950494}, {p: 2146203649, g: 712865423, s: 1170834574}, {p: 2146154497, g: 1764991362, s: 1064856763}, {p: 2146142209, g: 627386213, s: 1406840151}, {p: 2146127873, g: 1638674429, s: 2088393537}, {p: 2146099201, g: 1516001018, s: 690673370}, {p: 2146093057, g: 1294931393, s: 315136610}, {p: 2146091009, g: 1942399533, s: 973539425}, {p: 2146078721, g: 1843461814, s: 2132275436}, {p: 2146060289, g: 1098740778, s: 360423481}, {p: 2146048001, g: 1617213232, s: 1951981294}, {p: 2146041857, g: 1805783169, s: 2075683489}, {p: 2146019329, g: 272027909, s: 1753219918}, {p: 2145986561, g: 1206530344, s: 2034028118}, {p: 2145976321, g: 1243769360, s: 1173377644}, {p: 2145964033, g: 887200839, s: 1281344586}, {p: 2145906689, g: 1651026455, s: 906178216}, {p: 2145875969, g: 1673238256, s: 1043521212}, {p: 2145871873, g: 1226591210, s: 1399796492}, {p: 2145841153, g: 1465353397, s: 1324527802}, {p: 2145832961, g: 1150638905, s: 554084759}, {p: 2145816577, g: 221601706, s: 427340863}, {p: 2145785857, g: 608896761, s: 316590738}, {p: 2145755137, g: 1712054942, s: 1684294304}, {p: 2145742849, g: 1302302867, s: 724873116}, {p: 2145728513, g: 516717693, s: 431671476}, {p: 2145699841, g: 524575579, s: 1619722537}, {p: 2145691649, g: 1925625239, s: 982974435}, {p: 2145687553, g: 463795662, s: 1293154300}, {p: 2145673217, g: 771716636, s: 881778029}, {p: 2145630209, g: 1509556977, s: 837364988}, {p: 2145595393, g: 229091856, s: 851648427}, {p: 2145587201, g: 1796903241, s: 635342424}, {p: 2145525761, g: 715310882, s: 1677228081}, {p: 2145495041, g: 1040930522, s: 200685896}, {p: 2145466369, g: 949804237, s: 1809146322}, {p: 2145445889, g: 1673903706, s: 95316881}, {p: 2145390593, g: 806941852, s: 1428671135}, {p: 2145372161, g: 1402525292, s: 159350694}, {p: 2145361921, g: 2124760298, s: 1589134749}, {p: 2145359873, g: 1217503067, s: 1561543010}, {p: 2145355777, g: 338341402, s: 83865711}, {p: 2145343489, g: 1381532164, s: 641430002}, {p: 2145325057, g: 1883895478, s: 1528469895}, {p: 2145318913, g: 1335370424, s: 65809740}, {p: 2145312769, g: 2000008042, s: 1919775760}, {p: 2145300481, g: 961450962, s: 1229540578}, {p: 2145282049, g: 910466767, s: 1964062701}, {p: 2145232897, g: 816527501, s: 450152063}, {p: 2145218561, g: 1435128058, s: 1794509700}, {p: 2145187841, g: 33505311, s: 1272467582}, {p: 2145181697, g: 269767433, s: 1380363849}, {p: 2145175553, g: 56386299, s: 1316870546}, {p: 2145079297, g: 2106880293, s: 1391797340}, {p: 2145021953, g: 1347906152, s: 720510798}, {p: 2145015809, g: 206769262, s: 1651459955}, {p: 2145003521, g: 1885513236, s: 1393381284}, {p: 2144960513, g: 1810381315, s: 31937275}, {p: 2144944129, g: 1306487838, s: 2019419520}, {p: 2144935937, g: 37304730, s: 1841489054}, {p: 2144894977, g: 1601434616, s: 157985831}, {p: 2144888833, g: 98749330, s: 2128592228}, {p: 2144880641, g: 1772327002, s: 2076128344}, {p: 2144864257, g: 1404514762, s: 2029969964}, {p: 2144827393, g: 801236594, s: 406627220}, {p: 2144806913, g: 349217443, s: 1501080290}, {p: 2144796673, g: 1542656776, s: 2084736519}, {p: 2144778241, g: 1210734884, s: 1746416203}, {p: 2144759809, g: 1146598851, s: 716464489}, {p: 2144757761, g: 286328400, s: 1823728177}, {p: 2144729089, g: 1347555695, s: 1836644881}, {p: 2144727041, g: 1795703790, s: 520296412}, {p: 2144696321, g: 1302475157, s: 852964281}, {p: 2144667649, g: 1075877614, s: 504992927}, {p: 2144573441, g: 198765808, s: 1617144982}, {p: 2144555009, g: 321528767, s: 155821259}, {p: 2144550913, g: 814139516, s: 1819937644}, {p: 2144536577, g: 571143206, s: 962942255}, {p: 2144524289, g: 1746733766, s: 2471321}, {p: 2144512001, g: 1821415077, s: 124190939}, {p: 2144468993, g: 917871546, s: 1260072806}, {p: 2144458753, g: 378417981, s: 1569240563}, {p: 2144421889, g: 175229668, s: 1825620763}, {p: 2144409601, g: 1699216963, s: 351648117}, {p: 2144370689, g: 1071885991, s: 958186029}, {p: 2144348161, g: 1763151227, s: 540353574}, {p: 2144335873, g: 1060214804, s: 919598847}, {p: 2144329729, g: 663515846, s: 1448552668}, {p: 2144327681, g: 1057776305, s: 590222840}, {p: 2144309249, g: 1705149168, s: 1459294624}, {p: 2144296961, g: 325823721, s: 1649016934}, {p: 2144290817, g: 738775789, s: 447427206}, {p: 2144243713, g: 962347618, s: 893050215}, {p: 2144237569, g: 1655257077, s: 900860862}, {p: 2144161793, g: 242206694, s: 1567868672}, {p: 2144155649, g: 769415308, s: 1247993134}, {p: 2144137217, g: 320492023, s: 515841070}, {p: 2144120833, g: 1639388522, s: 770877302}, {p: 2144071681, g: 1761785233, s: 964296120}, {p: 2144065537, g: 419817825, s: 204564472}, {p: 2144028673, g: 666050597, s: 2091019760}, {p: 2144010241, g: 1413657615, s: 1518702610}, {p: 2143952897, g: 1238327946, s: 475672271}, {p: 2143940609, g: 307063413, s: 1176750846}, {p: 2143918081, g: 2062905559, s: 786785803}, {p: 2143899649, g: 1338112849, s: 1562292083}, {p: 2143891457, g: 68149545, s: 87166451}, {p: 2143885313, g: 921750778, s: 394460854}, {p: 2143854593, g: 719766593, s: 133877196}, {p: 2143836161, g: 1149399850, s: 1861591875}, {p: 2143762433, g: 1848739366, s: 1335934145}, {p: 2143756289, g: 1326674710, s: 102999236}, {p: 2143713281, g: 808061791, s: 1156900308}, {p: 2143690753, g: 388399459, s: 1926468019}, {p: 2143670273, g: 1427891374, s: 1756689401}, {p: 2143666177, g: 1912173949, s: 986629565}, {p: 2143645697, g: 2041160111, s: 371842865}, {p: 2143641601, g: 1279906897, s: 2023974350}, {p: 2143635457, g: 720473174, s: 1389027526}, {p: 2143621121, g: 1298309455, s: 1732632006}, {p: 2143598593, g: 1548762216, s: 1825417506}, {p: 2143567873, g: 620475784, s: 1073787233}, {p: 2143561729, g: 1932954575, s: 949167309}, {p: 2143553537, g: 354315656, s: 1652037534}, {p: 2143541249, g: 577424288, s: 1097027618}, {p: 2143531009, g: 357862822, s: 478640055}, {p: 2143522817, g: 2017706025, s: 1550531668}, {p: 2143506433, g: 2078127419, s: 1824320165}, {p: 2143488001, g: 613475285, s: 1604011510}, {p: 2143469569, g: 1466594987, s: 502095196}, {p: 2143426561, g: 1115430331, s: 1044637111}, {p: 2143383553, g: 9778045, s: 1902463734}, {p: 2143377409, g: 1557401276, s: 2056861771}, {p: 2143363073, g: 652036455, s: 1965915971}, {p: 2143260673, g: 1464581171, s: 1523257541}, {p: 2143246337, g: 1876119649, s: 764541916}, {p: 2143209473, g: 1614992673, s: 1920672844}, {p: 2143203329, g: 981052047, s: 2049774209}, {p: 2143160321, g: 1847355533, s: 728535665}, {p: 2143129601, g: 965558457, s: 603052992}, {p: 2143123457, g: 2140817191, s: 8348679}, {p: 2143100929, g: 1547263683, s: 694209023}, {p: 2143092737, g: 643459066, s: 1979934533}, {p: 2143082497, g: 188603778, s: 2026175670}, {p: 2143062017, g: 1657329695, s: 377451099}, {p: 2143051777, g: 114967950, s: 979255473}, {p: 2143025153, g: 1698431342, s: 1449196896}, {p: 2143006721, g: 1862741675, s: 1739650365}, {p: 2142996481, g: 756660457, s: 996160050}, {p: 2142976001, g: 927864010, s: 1166847574}, {p: 2142965761, g: 905070557, s: 661974566}, {p: 2142916609, g: 40932754, s: 1787161127}, {p: 2142892033, g: 1987985648, s: 675335382}, {p: 2142885889, g: 797497211, s: 1323096997}, {p: 2142871553, g: 2068025830, s: 1411877159}, {p: 2142861313, g: 1217177090, s: 1438410687}, {p: 2142830593, g: 409906375, s: 1767860634}, {p: 2142803969, g: 1197788993, s: 359782919}, {p: 2142785537, g: 643817365, s: 513932862}, {p: 2142779393, g: 1717046338, s: 218943121}, {p: 2142724097, g: 89336830, s: 416687049}, {p: 2142707713, g: 5944581, s: 1356813523}, {p: 2142658561, g: 887942135, s: 2074011722}, {p: 2142638081, g: 151851972, s: 1647339939}, {p: 2142564353, g: 1691505537, s: 1483107336}, {p: 2142533633, g: 1989920200, s: 1135938817}, {p: 2142529537, g: 959263126, s: 1531961857}, {p: 2142527489, g: 453251129, s: 1725566162}, {p: 2142502913, g: 1536028102, s: 182053257}, {p: 2142498817, g: 570138730, s: 701443447}, {p: 2142416897, g: 326965800, s: 411931819}, {p: 2142363649, g: 1675665410, s: 1517191733}, {p: 2142351361, g: 968529566, s: 1575712703}, {p: 2142330881, g: 1384953238, s: 1769087884}, {p: 2142314497, g: 1977173242, s: 1833745524}, {p: 2142289921, g: 95082313, s: 1714775493}, {p: 2142283777, g: 109377615, s: 1070584533}, {p: 2142277633, g: 16960510, s: 702157145}, {p: 2142263297, g: 553850819, s: 431364395}, {p: 2142208001, g: 241466367, s: 2053967982}, {p: 2142164993, g: 1795661326, s: 1031836848}, {p: 2142097409, g: 1212530046, s: 712772031}, {p: 2142087169, g: 1763869720, s: 822276067}, {p: 2142078977, g: 644065713, s: 1765268066}, {p: 2142074881, g: 112671944, s: 643204925}, {p: 2142044161, g: 1387785471, s: 1297890174}, {p: 2142025729, g: 783885537, s: 1000425730}, {p: 2142011393, g: 905662232, s: 1679401033}, {p: 2141974529, g: 799788433, s: 468119557}, {p: 2141943809, g: 1932544124, s: 449305555}, {p: 2141933569, g: 1527403256, s: 841867925}, {p: 2141931521, g: 1247076451, s: 743823916}, {p: 2141902849, g: 1199660531, s: 401687910}, {p: 2141890561, g: 150132350, s: 1720336972}, {p: 2141857793, g: 1287438162, s: 663880489}, {p: 2141833217, g: 618017731, s: 1819208266}, {p: 2141820929, g: 999578638, s: 1403090096}, {p: 2141786113, g: 81834325, s: 1523542501}, {p: 2141771777, g: 120001928, s: 463556492}, {p: 2141759489, g: 122455485, s: 2124928282}, {p: 2141749249, g: 141986041, s: 940339153}, {p: 2141685761, g: 889088734, s: 477141499}, {p: 2141673473, g: 324212681, s: 1122558298}, {p: 2141669377, g: 1175806187, s: 1373818177}, {p: 2141655041, g: 1113654822, s: 296887082}, {p: 2141587457, g: 991103258, s: 1585913875}, {p: 2141583361, g: 1401451409, s: 1802457360}, {p: 2141575169, g: 1571977166, s: 712760980}, {p: 2141546497, g: 1107849376, s: 1250270109}, {p: 2141515777, g: 196544219, s: 356001130}, {p: 2141495297, g: 1733571506, s: 1060744866}, {p: 2141483009, g: 321552363, s: 1168297026}, {p: 2141458433, g: 505818251, s: 733225819}, {p: 2141360129, g: 1026840098, s: 948342276}, {p: 2141325313, g: 945133744, s: 2129965998}, {p: 2141317121, g: 1871100260, s: 1843844634}, {p: 2141286401, g: 1790639498, s: 1750465696}, {p: 2141267969, g: 1376858592, s: 186160720}, {p: 2141255681, g: 2129698296, s: 1876677959}, {p: 2141243393, g: 2138900688, s: 1340009628}, {p: 2141214721, g: 1933049835, s: 1087819477}, {p: 2141212673, g: 1898664939, s: 1786328049}, {p: 2141202433, g: 990234828, s: 940682169}, {p: 2141175809, g: 1406392421, s: 993089586}, {p: 2141165569, g: 1263518371, s: 289019479}, {p: 2141073409, g: 1485624211, s: 507864514}, {p: 2141052929, g: 1885134788, s: 311252465}, {p: 2141040641, g: 1285021247, s: 280941862}, {p: 2141028353, g: 1527610374, s: 375035110}, {p: 2141011969, g: 1400626168, s: 164696620}, {p: 2140999681, g: 632959608, s: 966175067}, {p: 2140997633, g: 2045628978, s: 1290889438}, {p: 2140993537, g: 1412755491, s: 375366253}, {p: 2140942337, g: 719477232, s: 785367828}, {p: 2140925953, g: 45224252, s: 836552317}, {p: 2140917761, g: 1157376588, s: 1001839569}, {p: 2140887041, g: 278480752, s: 2098732796}, {p: 2140837889, g: 1663139953, s: 924094810}, {p: 2140788737, g: 802501511, s: 2045368990}, {p: 2140766209, g: 1820083885, s: 1800295504}, {p: 2140764161, g: 1169561905, s: 2106792035}, {p: 2140696577, g: 127781498, s: 1885987531}, {p: 2140684289, g: 16014477, s: 1098116827}, {p: 2140653569, g: 665960598, s: 1796728247}, {p: 2140594177, g: 1043085491, s: 377310938}, {p: 2140579841, g: 1732838211, s: 1504505945}, {p: 2140569601, g: 302071939, s: 358291016}, {p: 2140567553, g: 192393733, s: 1909137143}, {p: 2140557313, g: 406595731, s: 1175330270}, {p: 2140549121, g: 1748850918, s: 525007007}, {p: 2140477441, g: 499436566, s: 1031159814}, {p: 2140469249, g: 1886004401, s: 1029951320}, {p: 2140426241, g: 1483168100, s: 1676273461}, {p: 2140420097, g: 1779917297, s: 846024476}, {p: 2140413953, g: 522948893, s: 1816354149}, {p: 2140383233, g: 1931364473, s: 1296921241}, {p: 2140366849, g: 1917356555, s: 147196204}, {p: 2140354561, g: 16466177, s: 1349052107}, {p: 2140348417, g: 1875366972, s: 1860485634}, {p: 2140323841, g: 456498717, s: 1790256483}, {p: 2140321793, g: 1629493973, s: 150031888}, {p: 2140315649, g: 1904063898, s: 395510935}, {p: 2140280833, g: 1784104328, s: 831417909}, {p: 2140250113, g: 256087139, s: 697349101}, {p: 2140229633, g: 388553070, s: 243875754}, {p: 2140223489, g: 747459608, s: 1396270850}, {p: 2140200961, g: 507423743, s: 1895572209}, {p: 2140162049, g: 580106016, s: 2045297469}, {p: 2140149761, g: 712426444, s: 785217995}, {p: 2140137473, g: 1441607584, s: 536866543}, {p: 2140119041, g: 346538902, s: 1740434653}, {p: 2140090369, g: 282642885, s: 21051094}, {p: 2140076033, g: 1407456228, s: 319910029}, {p: 2140047361, g: 1619330500, s: 1488632070}, {p: 2140041217, g: 2089408064, s: 2012026134}, {p: 2140008449, g: 1705524800, s: 1613440760}, {p: 2139924481, g: 1846208233, s: 1280649481}, {p: 2139906049, g: 989438755, s: 1185646076}, {p: 2139867137, g: 1522314850, s: 372783595}, {p: 2139842561, g: 1681587377, s: 216848235}, {p: 2139826177, g: 2066284988, s: 1784999464}, {p: 2139824129, g: 480888214, s: 1513323027}, {p: 2139789313, g: 847937200, s: 858192859}, {p: 2139783169, g: 1642000434, s: 1583261448}, {p: 2139770881, g: 940699589, s: 179702100}, {p: 2139768833, g: 315623242, s: 964612676}, {p: 2139666433, g: 331649203, s: 764666914}, {p: 2139641857, g: 2118730799, s: 1313764644}, {p: 2139635713, g: 519149027, s: 519212449}, {p: 2139598849, g: 1526413634, s: 1769667104}, {p: 2139574273, g: 551148610, s: 820739925}, {p: 2139568129, g: 1386800242, s: 472447405}, {p: 2139549697, g: 813760130, s: 1412328531}, {p: 2139537409, g: 1615286260, s: 1609362979}, {p: 2139475969, g: 1352559299, s: 1696720421}, {p: 2139455489, g: 1048691649, s: 1584935400}, {p: 2139432961, g: 836025845, s: 950121150}, {p: 2139424769, g: 1558281165, s: 1635486858}, {p: 2139406337, g: 1728402143, s: 1674423301}, {p: 2139396097, g: 1727715782, s: 1483470544}, {p: 2139383809, g: 1092853491, s: 1741699084}, {p: 2139369473, g: 690776899, s: 1242798709}, {p: 2139351041, g: 1768782380, s: 2120712049}, {p: 2139334657, g: 1739968247, s: 1427249225}, {p: 2139332609, g: 1547189119, s: 623011170}, {p: 2139310081, g: 1346827917, s: 1605466350}, {p: 2139303937, g: 369317948, s: 828392831}, {p: 2139301889, g: 1560417239, s: 1788073219}, {p: 2139283457, g: 1303121623, s: 595079358}, {p: 2139248641, g: 1354555286, s: 573424177}, {p: 2139240449, g: 60974056, s: 885781403}, {p: 2139222017, g: 355573421, s: 1221054839}, {p: 2139215873, g: 566477826, s: 1724006500}, {p: 2139150337, g: 871437673, s: 1609133294}, {p: 2139144193, g: 1478130914, s: 1137491905}, {p: 2139117569, g: 1854880922, s: 964728507}, {p: 2139076609, g: 202405335, s: 756508944}, {p: 2139062273, g: 1399715741, s: 884826059}, {p: 2139045889, g: 1051045798, s: 1202295476}, {p: 2139033601, g: 1707715206, s: 632234634}, {p: 2139006977, g: 2035853139, s: 231626690}, {p: 2138951681, g: 183867876, s: 838350879}, {p: 2138945537, g: 1403254661, s: 404460202}, {p: 2138920961, g: 310865011, s: 1282911681}, {p: 2138910721, g: 1328496553, s: 103472415}, {p: 2138904577, g: 78831681, s: 993513549}, {p: 2138902529, g: 1319697451, s: 1055904361}, {p: 2138816513, g: 384338872, s: 1706202469}, {p: 2138810369, g: 1084868275, s: 405677177}, {p: 2138787841, g: 401181788, s: 1964773901}, {p: 2138775553, g: 1850532988, s: 1247087473}, {p: 2138767361, g: 874261901, s: 1576073565}, {p: 2138757121, g: 1187474742, s: 993541415}, {p: 2138748929, g: 1782458888, s: 1043206483}, {p: 2138744833, g: 1221500487, s: 800141243}, {p: 2138738689, g: 413465368, s: 1450660558}, {p: 2138695681, g: 739045140, s: 342611472}, {p: 2138658817, g: 1355845756, s: 672674190}, {p: 2138644481, g: 608379162, s: 1538874380}, {p: 2138632193, g: 1444914034, s: 686911254}, {p: 2138607617, g: 484707818, s: 1435142134}, {p: 2138591233, g: 539460669, s: 1290458549}, {p: 2138572801, g: 2093538990, s: 2011138646}, {p: 2138552321, g: 1149786988, s: 1076414907}, {p: 2138546177, g: 840688206, s: 2108985273}, {p: 2138533889, g: 209669619, s: 198172413}, {p: 2138523649, g: 1975879426, s: 1277003968}, {p: 2138490881, g: 1351891144, s: 1976858109}, {p: 2138460161, g: 1817321013, s: 1979278293}, {p: 2138429441, g: 1950077177, s: 203441928}, {p: 2138400769, g: 908970113, s: 628395069}, {p: 2138398721, g: 219890864, s: 758486760}, {p: 2138376193, g: 1306654379, s: 977554090}, {p: 2138351617, g: 298822498, s: 2004708503}, {p: 2138337281, g: 441457816, s: 1049002108}, {p: 2138320897, g: 1517731724, s: 1442269609}, {p: 2138290177, g: 1355911197, s: 1647139103}, {p: 2138234881, g: 531313247, s: 1746591962}, {p: 2138214401, g: 1899410930, s: 781416444}, {p: 2138202113, g: 1813477173, s: 1622508515}, {p: 2138191873, g: 1086458299, s: 1025408615}, {p: 2138183681, g: 1998800427, s: 827063290}, {p: 2138173441, g: 1921308898, s: 749670117}, {p: 2138103809, g: 1620902804, s: 2126787647}, {p: 2138099713, g: 828647069, s: 1892961817}, {p: 2138085377, g: 179405355, s: 1525506535}, {p: 2138060801, g: 615683235, s: 1259580138}, {p: 2138044417, g: 2030277840, s: 1731266562}, {p: 2138042369, g: 2087222316, s: 1627902259}, {p: 2138032129, g: 126388712, s: 1108640984}, {p: 2138011649, g: 715026550, s: 1017980050}, {p: 2137993217, g: 1693714349, s: 1351778704}, {p: 2137888769, g: 1289762259, s: 1053090405}, {p: 2137853953, g: 199991890, s: 1254192789}, {p: 2137833473, g: 941421685, s: 896995556}, {p: 2137817089, g: 750416446, s: 1251031181}, {p: 2137792513, g: 798075119, s: 368077456}, {p: 2137786369, g: 878543495, s: 1035375025}, {p: 2137767937, g: 9351178, s: 1156563902}, {p: 2137755649, g: 1382297614, s: 1686559583}, {p: 2137724929, g: 1345472850, s: 1681096331}, {p: 2137704449, g: 834666929, s: 630551727}, {p: 2137673729, g: 1646165729, s: 1892091571}, {p: 2137620481, g: 778943821, s: 48456461}, {p: 2137618433, g: 1730837875, s: 1713336725}, {p: 2137581569, g: 805610339, s: 1378891359}, {p: 2137538561, g: 204342388, s: 1950165220}, {p: 2137526273, g: 1947629754, s: 1500789441}, {p: 2137516033, g: 719902645, s: 1499525372}, {p: 2137491457, g: 230451261, s: 556382829}, {p: 2137440257, g: 979573541, s: 412760291}, {p: 2137374721, g: 927841248, s: 1954137185}, {p: 2137362433, g: 1243778559, s: 861024672}, {p: 2137313281, g: 1341338501, s: 980638386}, {p: 2137311233, g: 937415182, s: 1793212117}, {p: 2137255937, g: 795331324, s: 1410253405}, {p: 2137243649, g: 150756339, s: 1966999887}, {p: 2137182209, g: 163346914, s: 1939301431}, {p: 2137171969, g: 1952552395, s: 758913141}, {p: 2137159681, g: 570788721, s: 218668666}, {p: 2137147393, g: 1896656810, s: 2045670345}, {p: 2137141249, g: 358493842, s: 518199643}, {p: 2137139201, g: 1505023029, s: 674695848}, {p: 2137133057, g: 27911103, s: 830956306}, {p: 2137122817, g: 439771337, s: 1555268614}, {p: 2137116673, g: 790988579, s: 1871449599}, {p: 2137110529, g: 432109234, s: 811805080}, {p: 2137102337, g: 1357900653, s: 1184997641}, {p: 2137098241, g: 515119035, s: 1715693095}, {p: 2137090049, g: 408575203, s: 2085660657}, {p: 2137085953, g: 2097793407, s: 1349626963}, {p: 2137055233, g: 1556739954, s: 1449960883}, {p: 2137030657, g: 1545758650, s: 1369303716}, {p: 2136987649, g: 332602570, s: 103875114}, {p: 2136969217, g: 1499989506, s: 1662964115}, {p: 2136924161, g: 857040753, s: 4738842}, {p: 2136895489, g: 1948872712, s: 570436091}, {p: 2136893441, g: 58969960, s: 1568349634}, {p: 2136887297, g: 2127193379, s: 273612548}, {p: 2136850433, g: 111208983, s: 1181257116}, {p: 2136809473, g: 1627275942, s: 1680317971}, {p: 2136764417, g: 1574888217, s: 14011331}, {p: 2136741889, g: 14011055, s: 1129154251}, {p: 2136727553, g: 35862563, s: 1838555253}, {p: 2136721409, g: 310235666, s: 1363928244}, {p: 2136698881, g: 1612429202, s: 1560383828}, {p: 2136649729, g: 1138540131, s: 800014364}, {p: 2136606721, g: 602323503, s: 1433096652}, {p: 2136563713, g: 182209265, s: 1919611038}, {p: 2136555521, g: 324156477, s: 165591039}, {p: 2136549377, g: 195513113, s: 217165345}, {p: 2136526849, g: 1050768046, s: 939647887}, {p: 2136508417, g: 1886286237, s: 1619926572}, {p: 2136477697, g: 609647664, s: 35065157}, {p: 2136471553, g: 679352216, s: 1452259468}, {p: 2136457217, g: 128630031, s: 824816521}, {p: 2136422401, g: 19787464, s: 1526049830}, {p: 2136420353, g: 698316836, s: 1530623527}, {p: 2136371201, g: 1651862373, s: 1804812805}, {p: 2136334337, g: 326596005, s: 336977082}, {p: 2136322049, g: 63253370, s: 1904972151}, {p: 2136297473, g: 312176076, s: 172182411}, {p: 2136248321, g: 381261841, s: 369032670}, {p: 2136242177, g: 358688773, s: 1640007994}, {p: 2136229889, g: 512677188, s: 75585225}, {p: 2136219649, g: 2095003250, s: 1970086149}, {p: 2136207361, g: 1909650722, s: 537760675}, {p: 2136176641, g: 1334616195, s: 1533487619}, {p: 2136158209, g: 2096285632, s: 1793285210}, {p: 2136143873, g: 1897347517, s: 293843959}, {p: 2136133633, g: 923586222, s: 1022655978}, {p: 2136096769, g: 1464868191, s: 1515074410}, {p: 2136094721, g: 2020679520, s: 2061636104}, {p: 2136076289, g: 290798503, s: 1814726809}, {p: 2136041473, g: 156415894, s: 1250757633}, {p: 2135996417, g: 297459940, s: 1132158924}, {p: 2135955457, g: 538755304, s: 1688831340}, {}}

func modp_set(x int32, p uint32) uint32 {
	var w uint32
	w = uint32(x)
	w += uint32(int32(int(p) & int(uint32(int32(-(int(w) >> 31))))))
	return w
}
func modp_norm(x uint32, p uint32) int32 {
	return int32(int(x) - (int(p) & (((int(x) - ((int(p) + 1) >> 1)) >> 31) - 1)))
}
func modp_ninv31(p uint32) uint32 {
	var y uint32
	y = uint32(int32(2 - int(p)))
	y *= uint32(int32(2 - int(p)*int(y)))
	y *= uint32(int32(2 - int(p)*int(y)))
	y *= uint32(int32(2 - int(p)*int(y)))
	y *= uint32(int32(2 - int(p)*int(y)))
	return uint32(int32(int(-y) & 0x7FFFFFFF))
}
func modp_R(p uint32) uint32 {
	return uint32(int32((1 << 31) - int(p)))
}
func modp_add(a uint32, b uint32, p uint32) uint32 {
	var d uint32
	d = uint32(int32(int(a) + int(b) - int(p)))
	d += uint32(int32(int(p) & int(uint32(int32(-(int(d) >> 31))))))
	return d
}
func modp_sub(a uint32, b uint32, p uint32) uint32 {
	var d uint32
	d = uint32(int32(int(a) - int(b)))
	d += uint32(int32(int(p) & int(uint32(int32(-(int(d) >> 31))))))
	return d
}
func modp_montymul(a uint32, b uint32, p uint32, p0i uint32) uint32 {
	var (
		z uint64
		w uint64
		d uint32
	)
	z = uint64(a) * uint64(b)
	w = ((z * uint64(p0i)) & 0x7FFFFFFF) * uint64(p)
	d = uint32(int32(int(uint32((z+w)>>31)) - int(p)))
	d += uint32(int32(int(p) & int(uint32(int32(-(int(d) >> 31))))))
	return d
}
func modp_R2(p uint32, p0i uint32) uint32 {
	var z uint32
	z = modp_R(p)
	z = modp_add(z, z, p)
	z = modp_montymul(z, z, p, p0i)
	z = modp_montymul(z, z, p, p0i)
	z = modp_montymul(z, z, p, p0i)
	z = modp_montymul(z, z, p, p0i)
	z = modp_montymul(z, z, p, p0i)
	z = uint32(int32((int(z) + (int(p) & (-(int(z) & 1)))) >> 1))
	return z
}
func modp_Rx(x uint, p uint32, p0i uint32, R2 uint32) uint32 {
	var (
		i int
		r uint32
		z uint32
	)
	x--
	r = R2
	z = modp_R(p)
	for i = 0; (1 << i) <= int(x); i++ {
		if (x & uint(1<<i)) != 0 {
			z = modp_montymul(z, r, p, p0i)
		}
		r = modp_montymul(r, r, p, p0i)
	}
	return z
}
func modp_div(a uint32, b uint32, p uint32, p0i uint32, R uint32) uint32 {
	var (
		z uint32
		e uint32
		i int
	)
	e = uint32(int32(int(p) - 2))
	z = R
	for i = 30; i >= 0; i-- {
		var z2 uint32
		z = modp_montymul(z, z, p, p0i)
		z2 = modp_montymul(z, b, p, p0i)
		z ^= uint32(int32((int(z) ^ int(z2)) & int(-uint32(int32((int(e)>>i)&1)))))
	}
	z = modp_montymul(z, 1, p, p0i)
	return modp_montymul(a, z, p, p0i)
}

var REV10 [1024]uint16 = [1024]uint16{0, 512, 256, 768, 128, 640, 384, 896, 64, 576, 320, 832, 192, 704, 448, 960, 32, 544, 288, 800, 160, 672, 416, 928, 96, 608, 352, 864, 224, 736, 480, 992, 16, 528, 272, 784, 144, 656, 400, 912, 80, 592, 336, 848, 208, 720, 464, 976, 48, 560, 304, 816, 176, 688, 432, 944, 112, 624, 368, 880, 240, 752, 496, 1008, 8, 520, 264, 776, 136, 648, 392, 904, 72, 584, 328, 840, 200, 712, 456, 968, 40, 552, 296, 808, 168, 680, 424, 936, 104, 616, 360, 872, 232, 744, 488, 1000, 24, 536, 280, 792, 152, 664, 408, 920, 88, 600, 344, 856, 216, 728, 472, 984, 56, 568, 312, 824, 184, 696, 440, 952, 120, 632, 376, 888, 248, 760, 504, 1016, 4, 516, 260, 772, 132, 644, 388, 900, 68, 580, 324, 836, 196, 708, 452, 964, 36, 548, 292, 804, 164, 676, 420, 932, 100, 612, 356, 868, 228, 740, 484, 996, 20, 532, 276, 788, 148, 660, 404, 916, 84, 596, 340, 852, 212, 724, 468, 980, 52, 564, 308, 820, 180, 692, 436, 948, 116, 628, 372, 884, 244, 756, 500, 1012, 12, 524, 268, 780, 140, 652, 396, 908, 76, 588, 332, 844, 204, 716, 460, 972, 44, 556, 300, 812, 172, 684, 428, 940, 108, 620, 364, 876, 236, 748, 492, 1004, 28, 540, 284, 796, 156, 668, 412, 924, 92, 604, 348, 860, 220, 732, 476, 988, 60, 572, 316, 828, 188, 700, 444, 956, 124, 636, 380, 892, 252, 764, 508, 1020, 2, 514, 258, 770, 130, 642, 386, 898, 66, 578, 322, 834, 194, 706, 450, 962, 34, 546, 290, 802, 162, 674, 418, 930, 98, 610, 354, 866, 226, 738, 482, 994, 18, 530, 274, 786, 146, 658, 402, 914, 82, 594, 338, 850, 210, 722, 466, 978, 50, 562, 306, 818, 178, 690, 434, 946, 114, 626, 370, 882, 242, 754, 498, 1010, 10, 522, 266, 778, 138, 650, 394, 906, 74, 586, 330, 842, 202, 714, 458, 970, 42, 554, 298, 810, 170, 682, 426, 938, 106, 618, 362, 874, 234, 746, 490, 1002, 26, 538, 282, 794, 154, 666, 410, 922, 90, 602, 346, 858, 218, 730, 474, 986, 58, 570, 314, 826, 186, 698, 442, 954, 122, 634, 378, 890, 250, 762, 506, 1018, 6, 518, 262, 774, 134, 646, 390, 902, 70, 582, 326, 838, 198, 710, 454, 966, 38, 550, 294, 806, 166, 678, 422, 934, 102, 614, 358, 870, 230, 742, 486, 998, 22, 534, 278, 790, 150, 662, 406, 918, 86, 598, 342, 854, 214, 726, 470, 982, 54, 566, 310, 822, 182, 694, 438, 950, 118, 630, 374, 886, 246, 758, 502, 1014, 14, 526, 270, 782, 142, 654, 398, 910, 78, 590, 334, 846, 206, 718, 462, 974, 46, 558, 302, 814, 174, 686, 430, 942, 110, 622, 366, 878, 238, 750, 494, 1006, 30, 542, 286, 798, 158, 670, 414, 926, 94, 606, 350, 862, 222, 734, 478, 990, 62, 574, 318, 830, 190, 702, 446, 958, 126, 638, 382, 894, 254, 766, 510, 1022, 1, 513, 257, 769, 129, 641, 385, 897, 65, 577, 321, 833, 193, 705, 449, 961, 33, 545, 289, 801, 161, 673, 417, 929, 97, 609, 353, 865, 225, 737, 481, 993, 17, 529, 273, 785, 145, 657, 401, 913, 81, 593, 337, 849, 209, 721, 465, 977, 49, 561, 305, 817, 177, 689, 433, 945, 113, 625, 369, 881, 241, 753, 497, 1009, 9, 521, 265, 777, 137, 649, 393, 905, 73, 585, 329, 841, 201, 713, 457, 969, 41, 553, 297, 809, 169, 681, 425, 937, 105, 617, 361, 873, 233, 745, 489, 1001, 25, 537, 281, 793, 153, 665, 409, 921, 89, 601, 345, 857, 217, 729, 473, 985, 57, 569, 313, 825, 185, 697, 441, 953, 121, 633, 377, 889, 249, 761, 505, 1017, 5, 517, 261, 773, 133, 645, 389, 901, 69, 581, 325, 837, 197, 709, 453, 965, 37, 549, 293, 805, 165, 677, 421, 933, 101, 613, 357, 869, 229, 741, 485, 997, 21, 533, 277, 789, 149, 661, 405, 917, 85, 597, 341, 853, 213, 725, 469, 981, 53, 565, 309, 821, 181, 693, 437, 949, 117, 629, 373, 885, 245, 757, 501, 1013, 13, 525, 269, 781, 141, 653, 397, 909, 77, 589, 333, 845, 205, 717, 461, 973, 45, 557, 301, 813, 173, 685, 429, 941, 109, 621, 365, 877, 237, 749, 493, 1005, 29, 541, 285, 797, 157, 669, 413, 925, 93, 605, 349, 861, 221, 733, 477, 989, 61, 573, 317, 829, 189, 701, 445, 957, 125, 637, 381, 893, 253, 765, 509, 1021, 3, 515, 259, 771, 131, 643, 387, 899, 67, 579, 323, 835, 195, 707, 451, 963, 35, 547, 291, 803, 163, 675, 419, 931, 99, 611, 355, 867, 227, 739, 483, 995, 19, 531, 275, 787, 147, 659, 403, 915, 83, 595, 339, 851, 211, 723, 467, 979, 51, 563, 307, 819, 179, 691, 435, 947, 115, 627, 371, 883, 243, 755, 499, 1011, 11, 523, 267, 779, 139, 651, 395, 907, 75, 587, 331, 843, 203, 715, 459, 971, 43, 555, 299, 811, 171, 683, 427, 939, 107, 619, 363, 875, 235, 747, 491, 1003, 27, 539, 283, 795, 155, 667, 411, 923, 91, 603, 347, 859, 219, 731, 475, 987, 59, 571, 315, 827, 187, 699, 443, 955, 123, 635, 379, 891, 251, 763, 507, 1019, 7, 519, 263, 775, 135, 647, 391, 903, 71, 583, 327, 839, 199, 711, 455, 967, 39, 551, 295, 807, 167, 679, 423, 935, 103, 615, 359, 871, 231, 743, 487, 999, 23, 535, 279, 791, 151, 663, 407, 919, 87, 599, 343, 855, 215, 727, 471, 983, 55, 567, 311, 823, 183, 695, 439, 951, 119, 631, 375, 887, 247, 759, 503, 1015, 15, 527, 271, 783, 143, 655, 399, 911, 79, 591, 335, 847, 207, 719, 463, 975, 47, 559, 303, 815, 175, 687, 431, 943, 111, 623, 367, 879, 239, 751, 495, 1007, 31, 543, 287, 799, 159, 671, 415, 927, 95, 607, 351, 863, 223, 735, 479, 991, 63, 575, 319, 831, 191, 703, 447, 959, 127, 639, 383, 895, 255, 767, 511, 1023}

func modp_mkgm2(gm *uint32, igm *uint32, logn uint, g uint32, p uint32, p0i uint32) {
	var (
		u  uint64
		n  uint64
		k  uint
		ig uint32
		x1 uint32
		x2 uint32
		R2 uint32
	)
	n = uint64(1 << logn)
	R2 = modp_R2(p, p0i)
	g = modp_montymul(g, R2, p, p0i)
	for k = logn; k < 10; k++ {
		g = modp_montymul(g, g, p, p0i)
	}
	ig = modp_div(R2, g, p, p0i, modp_R(p))
	k = 10 - logn
	x1 = func() uint32 {
		x2 = modp_R(p)
		return x2
	}()
	for u = 0; u < n; u++ {
		var v uint64
		v = uint64(REV10[u<<uint64(k)])
		*(*uint32)(unsafe.Add(unsafe.Pointer(gm), unsafe.Sizeof(uint32(0))*uintptr(v))) = x1
		*(*uint32)(unsafe.Add(unsafe.Pointer(igm), unsafe.Sizeof(uint32(0))*uintptr(v))) = x2
		x1 = modp_montymul(x1, g, p, p0i)
		x2 = modp_montymul(x2, ig, p, p0i)
	}
}
func modp_NTT2_ext(a *uint32, stride uint64, gm *uint32, logn uint, p uint32, p0i uint32) {
	var (
		t uint64
		m uint64
		n uint64
	)
	if logn == 0 {
		return
	}
	n = uint64(1 << logn)
	t = n
	for m = 1; m < n; m <<= 1 {
		var (
			ht uint64
			u  uint64
			v1 uint64
		)
		ht = t >> 1
		for func() uint64 {
			u = 0
			return func() uint64 {
				v1 = 0
				return v1
			}()
		}(); u < m; func() uint64 {
			u++
			return func() uint64 {
				v1 += t
				return v1
			}()
		}() {
			var (
				s  uint32
				v  uint64
				r1 *uint32
				r2 *uint32
			)
			s = *(*uint32)(unsafe.Add(unsafe.Pointer(gm), unsafe.Sizeof(uint32(0))*uintptr(m+u)))
			r1 = (*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(v1*stride)))
			r2 = (*uint32)(unsafe.Add(unsafe.Pointer(r1), unsafe.Sizeof(uint32(0))*uintptr(ht*stride)))
			for v = 0; v < ht; func() *uint32 {
				v++
				r1 = (*uint32)(unsafe.Add(unsafe.Pointer(r1), unsafe.Sizeof(uint32(0))*uintptr(stride)))
				return func() *uint32 {
					r2 = (*uint32)(unsafe.Add(unsafe.Pointer(r2), unsafe.Sizeof(uint32(0))*uintptr(stride)))
					return r2
				}()
			}() {
				var (
					x uint32
					y uint32
				)
				x = *r1
				y = modp_montymul(*r2, s, p, p0i)
				*r1 = modp_add(x, y, p)
				*r2 = modp_sub(x, y, p)
			}
		}
		t = ht
	}
}
func modp_iNTT2_ext(a *uint32, stride uint64, igm *uint32, logn uint, p uint32, p0i uint32) {
	var (
		t  uint64
		m  uint64
		n  uint64
		k  uint64
		ni uint32
		r  *uint32
	)
	if logn == 0 {
		return
	}
	n = uint64(1 << logn)
	t = 1
	for m = n; m > 1; m >>= 1 {
		var (
			hm uint64
			dt uint64
			u  uint64
			v1 uint64
		)
		hm = m >> 1
		dt = t << 1
		for func() uint64 {
			u = 0
			return func() uint64 {
				v1 = 0
				return v1
			}()
		}(); u < hm; func() uint64 {
			u++
			return func() uint64 {
				v1 += dt
				return v1
			}()
		}() {
			var (
				s  uint32
				v  uint64
				r1 *uint32
				r2 *uint32
			)
			s = *(*uint32)(unsafe.Add(unsafe.Pointer(igm), unsafe.Sizeof(uint32(0))*uintptr(hm+u)))
			r1 = (*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(v1*stride)))
			r2 = (*uint32)(unsafe.Add(unsafe.Pointer(r1), unsafe.Sizeof(uint32(0))*uintptr(t*stride)))
			for v = 0; v < t; func() *uint32 {
				v++
				r1 = (*uint32)(unsafe.Add(unsafe.Pointer(r1), unsafe.Sizeof(uint32(0))*uintptr(stride)))
				return func() *uint32 {
					r2 = (*uint32)(unsafe.Add(unsafe.Pointer(r2), unsafe.Sizeof(uint32(0))*uintptr(stride)))
					return r2
				}()
			}() {
				var (
					x uint32
					y uint32
				)
				x = *r1
				y = *r2
				*r1 = modp_add(x, y, p)
				*r2 = modp_montymul(modp_sub(x, y, p), s, p, p0i)
			}
		}
		t = dt
	}
	ni = uint32(1 << (31 - logn))
	for func() *uint32 {
		k = 0
		return func() *uint32 {
			r = a
			return r
		}()
	}(); k < n; func() *uint32 {
		k++
		return func() *uint32 {
			r = (*uint32)(unsafe.Add(unsafe.Pointer(r), unsafe.Sizeof(uint32(0))*uintptr(stride)))
			return r
		}()
	}() {
		*r = modp_montymul(*r, ni, p, p0i)
	}
}
func modp_poly_rec_res(f *uint32, logn uint, p uint32, p0i uint32, R2 uint32) {
	var (
		hn uint64
		u  uint64
	)
	hn = uint64(1 << (logn - 1))
	for u = 0; u < hn; u++ {
		var (
			w0 uint32
			w1 uint32
		)
		w0 = *(*uint32)(unsafe.Add(unsafe.Pointer(f), unsafe.Sizeof(uint32(0))*uintptr((u<<1)+0)))
		w1 = *(*uint32)(unsafe.Add(unsafe.Pointer(f), unsafe.Sizeof(uint32(0))*uintptr((u<<1)+1)))
		*(*uint32)(unsafe.Add(unsafe.Pointer(f), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_montymul(modp_montymul(w0, w1, p, p0i), R2, p, p0i)
	}
}
func zint_sub(a *uint32, b *uint32, len_ uint64, ctl uint32) uint32 {
	var (
		u  uint64
		cc uint32
		m  uint32
	)
	cc = 0
	m = -ctl
	for u = 0; u < len_; u++ {
		var (
			aw uint32
			w  uint32
		)
		aw = *(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(u)))
		w = uint32(int32(int(aw) - int(*(*uint32)(unsafe.Add(unsafe.Pointer(b), unsafe.Sizeof(uint32(0))*uintptr(u)))) - int(cc)))
		cc = uint32(int32(int(w) >> 31))
		aw ^= uint32(int32(((int(w) & 0x7FFFFFFF) ^ int(aw)) & int(m)))
		*(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(u))) = aw
	}
	return cc
}
func zint_mul_small(m *uint32, mlen uint64, x uint32) uint32 {
	var (
		u  uint64
		cc uint32
	)
	cc = 0
	for u = 0; u < mlen; u++ {
		var z uint64
		z = uint64(*(*uint32)(unsafe.Add(unsafe.Pointer(m), unsafe.Sizeof(uint32(0))*uintptr(u))))*uint64(x) + uint64(cc)
		*(*uint32)(unsafe.Add(unsafe.Pointer(m), unsafe.Sizeof(uint32(0))*uintptr(u))) = uint32(int32(int(uint32(z)) & 0x7FFFFFFF))
		cc = uint32(z >> 31)
	}
	return cc
}
func zint_mod_small_unsigned(d *uint32, dlen uint64, p uint32, p0i uint32, R2 uint32) uint32 {
	var (
		x uint32
		u uint64
	)
	x = 0
	u = dlen
	for func() uint64 {
		p_ := &u
		x := *p_
		*p_--
		return x
	}() > 0 {
		var w uint32
		x = modp_montymul(x, R2, p, p0i)
		w = uint32(int32(int(*(*uint32)(unsafe.Add(unsafe.Pointer(d), unsafe.Sizeof(uint32(0))*uintptr(u)))) - int(p)))
		w += uint32(int32(int(p) & int(uint32(int32(-(int(w) >> 31))))))
		x = modp_add(x, w, p)
	}
	return x
}
func zint_mod_small_signed(d *uint32, dlen uint64, p uint32, p0i uint32, R2 uint32, Rx uint32) uint32 {
	var z uint32
	if dlen == 0 {
		return 0
	}
	z = zint_mod_small_unsigned(d, dlen, p, p0i, R2)
	z = modp_sub(z, uint32(int32(int(Rx)&int(uint32(int32(-(int(*(*uint32)(unsafe.Add(unsafe.Pointer(d), unsafe.Sizeof(uint32(0))*uintptr(dlen-1))))>>30)))))), p)
	return z
}
func zint_add_mul_small(x *uint32, y *uint32, len_ uint64, s uint32) {
	var (
		u  uint64
		cc uint32
	)
	cc = 0
	for u = 0; u < len_; u++ {
		var (
			xw uint32
			yw uint32
			z  uint64
		)
		xw = *(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(u)))
		yw = *(*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(u)))
		z = uint64(yw)*uint64(s) + uint64(xw) + uint64(cc)
		*(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(u))) = uint32(int32(int(uint32(z)) & 0x7FFFFFFF))
		cc = uint32(z >> 31)
	}
	*(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(len_))) = cc
}
func zint_norm_zero(x *uint32, p *uint32, len_ uint64) {
	var (
		u  uint64
		r  uint32
		bb uint32
	)
	r = 0
	bb = 0
	u = len_
	for func() uint64 {
		p_ := &u
		x := *p_
		*p_--
		return x
	}() > 0 {
		var (
			wx uint32
			wp uint32
			cc uint32
		)
		wx = *(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(u)))
		wp = uint32(int32((int(*(*uint32)(unsafe.Add(unsafe.Pointer(p), unsafe.Sizeof(uint32(0))*uintptr(u)))) >> 1) | int(bb)<<30))
		bb = uint32(int32(int(*(*uint32)(unsafe.Add(unsafe.Pointer(p), unsafe.Sizeof(uint32(0))*uintptr(u)))) & 1))
		cc = uint32(int32(int(wp) - int(wx)))
		cc = uint32(int32((int(-cc) >> 31) | int(uint32(int32(-(int(cc) >> 31))))))
		r |= uint32(int32(int(cc) & ((int(r) & 1) - 1)))
	}
	zint_sub(x, p, len_, uint32(int32(int(r)>>31)))
}
func zint_rebuild_CRT(xx *uint32, xlen uint64, xstride uint64, num uint64, primes *small_prime, normalize_signed int, tmp *uint32) {
	var (
		u uint64
		x *uint32
	)
	*(*uint32)(unsafe.Add(unsafe.Pointer(tmp), unsafe.Sizeof(uint32(0))*0)) = (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*0))).p
	for u = 1; u < xlen; u++ {
		var (
			p   uint32
			p0i uint32
			s   uint32
			R2  uint32
			v   uint64
		)
		p = (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*uintptr(u)))).p
		s = (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*uintptr(u)))).s
		p0i = modp_ninv31(p)
		R2 = modp_R2(p, p0i)
		for func() *uint32 {
			v = 0
			return func() *uint32 {
				x = xx
				return x
			}()
		}(); v < num; func() *uint32 {
			v++
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(xstride)))
				return x
			}()
		}() {
			var (
				xp uint32
				xq uint32
				xr uint32
			)
			xp = *(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(u)))
			xq = zint_mod_small_unsigned(x, u, p, p0i, R2)
			xr = modp_montymul(s, modp_sub(xp, xq, p), p, p0i)
			zint_add_mul_small(x, tmp, u, xr)
		}
		*(*uint32)(unsafe.Add(unsafe.Pointer(tmp), unsafe.Sizeof(uint32(0))*uintptr(u))) = zint_mul_small(tmp, u, p)
	}
	if normalize_signed != 0 {
		for func() *uint32 {
			u = 0
			return func() *uint32 {
				x = xx
				return x
			}()
		}(); u < num; func() *uint32 {
			u++
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(xstride)))
				return x
			}()
		}() {
			zint_norm_zero(x, tmp, xlen)
		}
	}
}
func zint_negate(a *uint32, len_ uint64, ctl uint32) {
	var (
		u  uint64
		cc uint32
		m  uint32
	)
	cc = ctl
	m = uint32(int32(int(-ctl) >> 1))
	for u = 0; u < len_; u++ {
		var aw uint32
		aw = *(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(u)))
		aw = uint32(int32((int(aw) ^ int(m)) + int(cc)))
		*(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(u))) = uint32(int32(int(aw) & 0x7FFFFFFF))
		cc = uint32(int32(int(aw) >> 31))
	}
}
func zint_co_reduce(a *uint32, b *uint32, len_ uint64, xa int64, xb int64, ya int64, yb int64) uint32 {
	var (
		u    uint64
		cca  int64
		ccb  int64
		nega uint32
		negb uint32
	)
	cca = 0
	ccb = 0
	for u = 0; u < len_; u++ {
		var (
			wa uint32
			wb uint32
			za uint64
			zb uint64
		)
		wa = *(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(u)))
		wb = *(*uint32)(unsafe.Add(unsafe.Pointer(b), unsafe.Sizeof(uint32(0))*uintptr(u)))
		za = uint64(wa)*uint64(xa) + uint64(wb)*uint64(xb) + uint64(cca)
		zb = uint64(wa)*uint64(ya) + uint64(wb)*uint64(yb) + uint64(ccb)
		if u > 0 {
			*(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(u-1))) = uint32(int32(int(uint32(za)) & 0x7FFFFFFF))
			*(*uint32)(unsafe.Add(unsafe.Pointer(b), unsafe.Sizeof(uint32(0))*uintptr(u-1))) = uint32(int32(int(uint32(zb)) & 0x7FFFFFFF))
		}
		cca = *(*int64)(unsafe.Pointer(&za)) >> 31
		ccb = *(*int64)(unsafe.Pointer(&zb)) >> 31
	}
	*(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(len_-1))) = uint32(int32(cca))
	*(*uint32)(unsafe.Add(unsafe.Pointer(b), unsafe.Sizeof(uint32(0))*uintptr(len_-1))) = uint32(int32(ccb))
	nega = uint32(uint64(cca) >> 63)
	negb = uint32(uint64(ccb) >> 63)
	zint_negate(a, len_, nega)
	zint_negate(b, len_, negb)
	return uint32(int32(int(nega) | int(negb)<<1))
}
func zint_finish_mod(a *uint32, len_ uint64, m *uint32, neg uint32) {
	var (
		u  uint64
		cc uint32
		xm uint32
		ym uint32
	)
	cc = 0
	for u = 0; u < len_; u++ {
		cc = uint32(int32((int(*(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(u)))) - int(*(*uint32)(unsafe.Add(unsafe.Pointer(m), unsafe.Sizeof(uint32(0))*uintptr(u)))) - int(cc)) >> 31))
	}
	xm = uint32(int32(int(-neg) >> 1))
	ym = uint32(int32(-(int(neg) | (1 - int(cc)))))
	cc = neg
	for u = 0; u < len_; u++ {
		var (
			aw uint32
			mw uint32
		)
		aw = *(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(u)))
		mw = uint32(int32((int(*(*uint32)(unsafe.Add(unsafe.Pointer(m), unsafe.Sizeof(uint32(0))*uintptr(u)))) ^ int(xm)) & int(ym)))
		aw = uint32(int32(int(aw) - int(mw) - int(cc)))
		*(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(u))) = uint32(int32(int(aw) & 0x7FFFFFFF))
		cc = uint32(int32(int(aw) >> 31))
	}
}
func zint_co_reduce_mod(a *uint32, b *uint32, m *uint32, len_ uint64, m0i uint32, xa int64, xb int64, ya int64, yb int64) {
	var (
		u   uint64
		cca int64
		ccb int64
		fa  uint32
		fb  uint32
	)
	cca = 0
	ccb = 0
	fa = uint32(int32(((int(*(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*0)))*int(uint32(int32(xa))) + int(*(*uint32)(unsafe.Add(unsafe.Pointer(b), unsafe.Sizeof(uint32(0))*0)))*int(uint32(int32(xb)))) * int(m0i)) & 0x7FFFFFFF))
	fb = uint32(int32(((int(*(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*0)))*int(uint32(int32(ya))) + int(*(*uint32)(unsafe.Add(unsafe.Pointer(b), unsafe.Sizeof(uint32(0))*0)))*int(uint32(int32(yb)))) * int(m0i)) & 0x7FFFFFFF))
	for u = 0; u < len_; u++ {
		var (
			wa uint32
			wb uint32
			za uint64
			zb uint64
		)
		wa = *(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(u)))
		wb = *(*uint32)(unsafe.Add(unsafe.Pointer(b), unsafe.Sizeof(uint32(0))*uintptr(u)))
		za = uint64(wa)*uint64(xa) + uint64(wb)*uint64(xb) + uint64(*(*uint32)(unsafe.Add(unsafe.Pointer(m), unsafe.Sizeof(uint32(0))*uintptr(u))))*uint64(fa) + uint64(cca)
		zb = uint64(wa)*uint64(ya) + uint64(wb)*uint64(yb) + uint64(*(*uint32)(unsafe.Add(unsafe.Pointer(m), unsafe.Sizeof(uint32(0))*uintptr(u))))*uint64(fb) + uint64(ccb)
		if u > 0 {
			*(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(u-1))) = uint32(int32(int(uint32(za)) & 0x7FFFFFFF))
			*(*uint32)(unsafe.Add(unsafe.Pointer(b), unsafe.Sizeof(uint32(0))*uintptr(u-1))) = uint32(int32(int(uint32(zb)) & 0x7FFFFFFF))
		}
		cca = *(*int64)(unsafe.Pointer(&za)) >> 31
		ccb = *(*int64)(unsafe.Pointer(&zb)) >> 31
	}
	*(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(len_-1))) = uint32(int32(cca))
	*(*uint32)(unsafe.Add(unsafe.Pointer(b), unsafe.Sizeof(uint32(0))*uintptr(len_-1))) = uint32(int32(ccb))
	zint_finish_mod(a, len_, m, uint32(uint64(cca)>>63))
	zint_finish_mod(b, len_, m, uint32(uint64(ccb)>>63))
}
func zint_bezout(u *uint32, v *uint32, x *uint32, y *uint32, len_ uint64, tmp *uint32) int {
	var (
		u0  *uint32
		u1  *uint32
		v0  *uint32
		v1  *uint32
		a   *uint32
		b   *uint32
		x0i uint32
		y0i uint32
		num uint32
		rc  uint32
		j   uint64
	)
	if len_ == 0 {
		return 0
	}
	u0 = u
	v0 = v
	u1 = tmp
	v1 = (*uint32)(unsafe.Add(unsafe.Pointer(u1), unsafe.Sizeof(uint32(0))*uintptr(len_)))
	a = (*uint32)(unsafe.Add(unsafe.Pointer(v1), unsafe.Sizeof(uint32(0))*uintptr(len_)))
	b = (*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(len_)))
	x0i = modp_ninv31(*(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*0)))
	y0i = modp_ninv31(*(*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*0)))
	libc.MemCpy(unsafe.Pointer(a), unsafe.Pointer(x), int(len_*uint64(unsafe.Sizeof(uint32(0)))))
	libc.MemCpy(unsafe.Pointer(b), unsafe.Pointer(y), int(len_*uint64(unsafe.Sizeof(uint32(0)))))
	*(*uint32)(unsafe.Add(unsafe.Pointer(u0), unsafe.Sizeof(uint32(0))*0)) = 1
	libc.MemSet(unsafe.Pointer((*uint32)(unsafe.Add(unsafe.Pointer(u0), unsafe.Sizeof(uint32(0))*1))), 0, int((len_-1)*uint64(unsafe.Sizeof(uint32(0)))))
	libc.MemSet(unsafe.Pointer(v0), 0, int(len_*uint64(unsafe.Sizeof(uint32(0)))))
	libc.MemCpy(unsafe.Pointer(u1), unsafe.Pointer(y), int(len_*uint64(unsafe.Sizeof(uint32(0)))))
	libc.MemCpy(unsafe.Pointer(v1), unsafe.Pointer(x), int(len_*uint64(unsafe.Sizeof(uint32(0)))))
	*(*uint32)(unsafe.Add(unsafe.Pointer(v1), unsafe.Sizeof(uint32(0))*0))--
	for num = uint32(int32(int(uint32(len_))*62 + 30)); int(num) >= 30; num -= 30 {
		var (
			c0   uint32
			c1   uint32
			a0   uint32
			a1   uint32
			b0   uint32
			b1   uint32
			a_hi uint64
			b_hi uint64
			a_lo uint32
			b_lo uint32
			pa   int64
			pb   int64
			qa   int64
			qb   int64
			i    int
			r    uint32
		)
		c0 = 4294967295
		c1 = 4294967295
		a0 = 0
		a1 = 0
		b0 = 0
		b1 = 0
		j = len_
		for func() uint64 {
			p_ := &j
			x := *p_
			*p_--
			return x
		}() > 0 {
			var (
				aw uint32
				bw uint32
			)
			aw = *(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(j)))
			bw = *(*uint32)(unsafe.Add(unsafe.Pointer(b), unsafe.Sizeof(uint32(0))*uintptr(j)))
			a0 ^= uint32(int32((int(a0) ^ int(aw)) & int(c0)))
			a1 ^= uint32(int32((int(a1) ^ int(aw)) & int(c1)))
			b0 ^= uint32(int32((int(b0) ^ int(bw)) & int(c0)))
			b1 ^= uint32(int32((int(b1) ^ int(bw)) & int(c1)))
			c1 = c0
			c0 &= uint32(int32((((int(aw) | int(bw)) + 0x7FFFFFFF) >> 31) - 1))
		}
		a1 |= uint32(int32(int(a0) & int(c1)))
		a0 &= ^c1
		b1 |= uint32(int32(int(b0) & int(c1)))
		b0 &= ^c1
		a_hi = (uint64(a0) << 31) + uint64(a1)
		b_hi = (uint64(b0) << 31) + uint64(b1)
		a_lo = *(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*0))
		b_lo = *(*uint32)(unsafe.Add(unsafe.Pointer(b), unsafe.Sizeof(uint32(0))*0))
		pa = 1
		pb = 0
		qa = 0
		qb = 1
		for i = 0; i < 31; i++ {
			var (
				rt  uint32
				oa  uint32
				ob  uint32
				cAB uint32
				cBA uint32
				cA  uint32
				rz  uint64
			)
			rz = b_hi - a_hi
			rt = uint32((rz ^ ((a_hi ^ b_hi) & (a_hi ^ rz))) >> 63)
			oa = uint32(int32((int(a_lo) >> i) & 1))
			ob = uint32(int32((int(b_lo) >> i) & 1))
			cAB = uint32(int32(int(oa) & int(ob) & int(rt)))
			cBA = uint32(int32(int(oa) & int(ob) & int(^rt)))
			cA = uint32(int32(int(cAB) | (int(oa) ^ 1)))
			a_lo -= uint32(int32(int(b_lo) & int(-cAB)))
			a_hi -= b_hi & (-uint64(cAB))
			pa -= qa & (-int64(cAB))
			pb -= qb & (-int64(cAB))
			b_lo -= uint32(int32(int(a_lo) & int(-cBA)))
			b_hi -= a_hi & (-uint64(cBA))
			qa -= pa & (-int64(cBA))
			qb -= pb & (-int64(cBA))
			a_lo += uint32(int32(int(a_lo) & (int(cA) - 1)))
			pa += pa & (int64(cA) - 1)
			pb += pb & (int64(cA) - 1)
			a_hi ^= (a_hi ^ a_hi>>1) & (-uint64(cA))
			b_lo += uint32(int32(int(b_lo) & int(-cA)))
			qa += qa & (-int64(cA))
			qb += qb & (-int64(cA))
			b_hi ^= (b_hi ^ b_hi>>1) & (uint64(cA) - 1)
		}
		r = zint_co_reduce(a, b, len_, pa, pb, qa, qb)
		pa -= (pa + pa) & (-int64(int(r) & 1))
		pb -= (pb + pb) & (-int64(int(r) & 1))
		qa -= (qa + qa) & (-int64(int(r) >> 1))
		qb -= (qb + qb) & (-int64(int(r) >> 1))
		zint_co_reduce_mod(u0, u1, y, len_, y0i, pa, pb, qa, qb)
		zint_co_reduce_mod(v0, v1, x, len_, x0i, pa, pb, qa, qb)
	}
	rc = uint32(int32(int(*(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*0))) ^ 1))
	for j = 1; j < len_; j++ {
		rc |= *(*uint32)(unsafe.Add(unsafe.Pointer(a), unsafe.Sizeof(uint32(0))*uintptr(j)))
	}
	return (1 - ((int(rc) | int(-rc)) >> 31)) & int(*(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*0))) & int(*(*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*0)))
}
func zint_add_scaled_mul_small(x *uint32, xlen uint64, y *uint32, ylen uint64, k int32, sch uint32, scl uint32) {
	var (
		u     uint64
		ysign uint32
		tw    uint32
		cc    int32
	)
	if ylen == 0 {
		return
	}
	ysign = uint32(int32(int(uint32(int32(-(int(*(*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(ylen-1)))) >> 30)))) >> 1))
	tw = 0
	cc = 0
	for u = uint64(sch); u < xlen; u++ {
		var (
			v   uint64
			wy  uint32
			wys uint32
			ccu uint32
			z   uint64
		)
		v = u - uint64(sch)
		if v < ylen {
			wy = *(*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(v)))
		} else {
			wy = ysign
		}
		wys = uint32(int32(((int(wy) << int(scl)) & 0x7FFFFFFF) | int(tw)))
		tw = uint32(int32(int(wy) >> (31 - int(scl))))
		z = uint64(int64(wys)*int64(k) + int64(*(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(u)))) + int64(cc))
		*(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(u))) = uint32(int32(int(uint32(z)) & 0x7FFFFFFF))
		ccu = uint32(z >> 31)
		cc = *(*int32)(unsafe.Pointer(&ccu))
	}
}
func zint_sub_scaled(x *uint32, xlen uint64, y *uint32, ylen uint64, sch uint32, scl uint32) {
	var (
		u     uint64
		ysign uint32
		tw    uint32
		cc    uint32
	)
	if ylen == 0 {
		return
	}
	ysign = uint32(int32(int(uint32(int32(-(int(*(*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(ylen-1)))) >> 30)))) >> 1))
	tw = 0
	cc = 0
	for u = uint64(sch); u < xlen; u++ {
		var (
			v   uint64
			w   uint32
			wy  uint32
			wys uint32
		)
		v = u - uint64(sch)
		if v < ylen {
			wy = *(*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(v)))
		} else {
			wy = ysign
		}
		wys = uint32(int32(((int(wy) << int(scl)) & 0x7FFFFFFF) | int(tw)))
		tw = uint32(int32(int(wy) >> (31 - int(scl))))
		w = uint32(int32(int(*(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(u)))) - int(wys) - int(cc)))
		*(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(u))) = uint32(int32(int(w) & 0x7FFFFFFF))
		cc = uint32(int32(int(w) >> 31))
	}
}
func zint_one_to_plain(x *uint32) int32 {
	var w uint32
	w = *(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*0))
	w |= uint32(int32((int(w) & 0x40000000) << 1))
	return *(*int32)(unsafe.Pointer(&w))
}
func poly_big_to_fp(d *fpr, f *uint32, flen uint64, fstride uint64, logn uint) {
	var (
		n uint64
		u uint64
	)
	n = uint64(1 << logn)
	if flen == 0 {
		for u = 0; u < n; u++ {
			*(*fpr)(unsafe.Add(unsafe.Pointer(d), unsafe.Sizeof(fpr(0))*uintptr(u))) = fpr_zero
		}
		return
	}
	for u = 0; u < n; func() *uint32 {
		u++
		return func() *uint32 {
			f = (*uint32)(unsafe.Add(unsafe.Pointer(f), unsafe.Sizeof(uint32(0))*uintptr(fstride)))
			return f
		}()
	}() {
		var (
			v   uint64
			neg uint32
			cc  uint32
			xm  uint32
			x   fpr
			fsc fpr
		)
		neg = uint32(int32(-(int(*(*uint32)(unsafe.Add(unsafe.Pointer(f), unsafe.Sizeof(uint32(0))*uintptr(flen-1)))) >> 30)))
		xm = uint32(int32(int(neg) >> 1))
		cc = uint32(int32(int(neg) & 1))
		x = fpr_zero
		fsc = fpr_one
		for v = 0; v < flen; func() fpr {
			v++
			return func() fpr {
				fsc = PQCLEAN_FALCON512_CLEAN_fpr_mul(fsc, fpr_ptwo31)
				return fsc
			}()
		}() {
			var w uint32
			w = uint32(int32((int(*(*uint32)(unsafe.Add(unsafe.Pointer(f), unsafe.Sizeof(uint32(0))*uintptr(v)))) ^ int(xm)) + int(cc)))
			cc = uint32(int32(int(w) >> 31))
			w &= 0x7FFFFFFF
			w -= uint32(int32((int(w) << 1) & int(neg)))
			x = PQCLEAN_FALCON512_CLEAN_fpr_add(x, PQCLEAN_FALCON512_CLEAN_fpr_mul(fpr_of(int64(*(*int32)(unsafe.Pointer(&w)))), fsc))
		}
		*(*fpr)(unsafe.Add(unsafe.Pointer(d), unsafe.Sizeof(fpr(0))*uintptr(u))) = x
	}
}
func poly_big_to_small(d *int8, s *uint32, lim int, logn uint) int {
	var (
		n uint64
		u uint64
	)
	n = uint64(1 << logn)
	for u = 0; u < n; u++ {
		var z int32
		z = zint_one_to_plain((*uint32)(unsafe.Add(unsafe.Pointer(s), unsafe.Sizeof(uint32(0))*uintptr(u))))
		if int(z) < -lim || int(z) > lim {
			return 0
		}
		*(*int8)(unsafe.Add(unsafe.Pointer(d), u)) = int8(z)
	}
	return 1
}
func poly_sub_scaled(F *uint32, Flen uint64, Fstride uint64, f *uint32, flen uint64, fstride uint64, k *int32, sch uint32, scl uint32, logn uint) {
	var (
		n uint64
		u uint64
	)
	n = uint64(1 << logn)
	for u = 0; u < n; u++ {
		var (
			kf int32
			v  uint64
			x  *uint32
			y  *uint32
		)
		kf = -*(*int32)(unsafe.Add(unsafe.Pointer(k), unsafe.Sizeof(int32(0))*uintptr(u)))
		x = (*uint32)(unsafe.Add(unsafe.Pointer(F), unsafe.Sizeof(uint32(0))*uintptr(u*Fstride)))
		y = f
		for v = 0; v < n; v++ {
			zint_add_scaled_mul_small(x, Flen, y, flen, kf, sch, scl)
			if u+v == n-1 {
				x = F
				kf = -kf
			} else {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(Fstride)))
			}
			y = (*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(fstride)))
		}
	}
}
func poly_sub_scaled_ntt(F *uint32, Flen uint64, Fstride uint64, f *uint32, flen uint64, fstride uint64, k *int32, sch uint32, scl uint32, logn uint, tmp *uint32) {
	var (
		gm     *uint32
		igm    *uint32
		fk     *uint32
		t1     *uint32
		x      *uint32
		y      *uint32
		n      uint64
		u      uint64
		tlen   uint64
		primes *small_prime
	)
	n = uint64(1 << logn)
	tlen = flen + 1
	gm = tmp
	igm = (*uint32)(unsafe.Add(unsafe.Pointer(gm), unsafe.Sizeof(uint32(0))*uintptr(1<<logn)))
	fk = (*uint32)(unsafe.Add(unsafe.Pointer(igm), unsafe.Sizeof(uint32(0))*uintptr(1<<logn)))
	t1 = (*uint32)(unsafe.Add(unsafe.Pointer(fk), unsafe.Sizeof(uint32(0))*uintptr(n*tlen)))
	primes = &PRIMES[0]
	for u = 0; u < tlen; u++ {
		var (
			p   uint32
			p0i uint32
			R2  uint32
			Rx  uint32
			v   uint64
		)
		p = (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*uintptr(u)))).p
		p0i = modp_ninv31(p)
		R2 = modp_R2(p, p0i)
		Rx = modp_Rx(uint(flen), p, p0i, R2)
		modp_mkgm2(gm, igm, logn, (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*uintptr(u)))).g, p, p0i)
		for v = 0; v < n; v++ {
			*(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr(v))) = modp_set(*(*int32)(unsafe.Add(unsafe.Pointer(k), unsafe.Sizeof(int32(0))*uintptr(v))), p)
		}
		modp_NTT2_ext(t1, 1, gm, logn, p, p0i)
		for func() *uint32 {
			v = 0
			y = f
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(fk), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return x
			}()
		}(); v < n; func() *uint32 {
			v++
			y = (*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(fstride)))
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(tlen)))
				return x
			}()
		}() {
			*x = zint_mod_small_signed(y, flen, p, p0i, R2, Rx)
		}
		modp_NTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(fk), unsafe.Sizeof(uint32(0))*uintptr(u))), tlen, gm, logn, p, p0i)
		for func() *uint32 {
			v = 0
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(fk), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return x
			}()
		}(); v < n; func() *uint32 {
			v++
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(tlen)))
				return x
			}()
		}() {
			*x = modp_montymul(modp_montymul(*(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr(v))), *x, p, p0i), R2, p, p0i)
		}
		modp_iNTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(fk), unsafe.Sizeof(uint32(0))*uintptr(u))), tlen, igm, logn, p, p0i)
	}
	zint_rebuild_CRT(fk, tlen, tlen, n, primes, 1, t1)
	for func() *uint32 {
		u = 0
		x = F
		return func() *uint32 {
			y = fk
			return y
		}()
	}(); u < n; func() *uint32 {
		u++
		x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(Fstride)))
		return func() *uint32 {
			y = (*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(tlen)))
			return y
		}()
	}() {
		zint_sub_scaled(x, Flen, y, tlen, sch, scl)
	}
}
func get_rng_u64(rng *shake256incctx) uint64 {
	var tmp [8]uint8
	shake256_inc_squeeze(&tmp[0], uint64(8), rng)
	return uint64(tmp[0]) | uint64(tmp[1])<<8 | uint64(tmp[2])<<16 | uint64(tmp[3])<<24 | uint64(tmp[4])<<32 | uint64(tmp[5])<<40 | uint64(tmp[6])<<48 | uint64(tmp[7])<<56
}

var gauss_1024_12289 [27]uint64 = [27]uint64{1283868770400643928, 6416574995475331444, 4078260278032692663, 2353523259288686585, 1227179971273316331, 575931623374121527, 242543240509105209, 91437049221049666, 30799446349977173, 9255276791179340, 2478152334826140, 590642893610164, 125206034929641, 23590435911403, 3948334035941, 586753615614, 77391054539, 9056793210, 940121950, 86539696, 7062824, 510971, 32764, 1862, 94, 4, 0}

func mkgauss(rng *shake256incctx, logn uint) int {
	var (
		u   uint
		g   uint
		val int
	)
	g = 1 << (10 - logn)
	val = 0
	for u = 0; u < g; u++ {
		var (
			r   uint64
			f   uint32
			v   uint32
			k   uint32
			neg uint32
		)
		r = get_rng_u64(rng)
		neg = uint32(r >> 63)
		r &= ^(uint64(1) << 63)
		f = uint32((r - gauss_1024_12289[0]) >> 63)
		v = 0
		r = get_rng_u64(rng)
		r &= ^(uint64(1) << 63)
		for k = 1; uintptr(k) < (unsafe.Sizeof([27]uint64{}))/(unsafe.Sizeof(uint64(0))); k++ {
			var t uint32
			t = uint32(int32(int(uint32((r-gauss_1024_12289[k])>>63)) ^ 1))
			v |= uint32(int32(int(k) & (-(int(t) & (int(f) ^ 1)))))
			f |= t
		}
		v = uint32(int32((int(v) ^ int(-neg)) + int(neg)))
		val += int(*(*int32)(unsafe.Pointer(&v)))
	}
	return val
}

var MAX_BL_SMALL [11]uint64 = [11]uint64{1, 1, 2, 2, 4, 7, 14, 27, 53, 106, 209}
var MAX_BL_LARGE [10]uint64 = [10]uint64{2, 2, 5, 7, 12, 21, 40, 78, 157, 308}
var BITLENGTH [11]struct {
	avg int
	std int
} = [11]struct {
	avg int
	std int
}{{avg: 4, std: 0}, {avg: 11, std: 1}, {avg: 24, std: 1}, {avg: 50, std: 1}, {avg: 102, std: 1}, {avg: 202, std: 2}, {avg: 401, std: 4}, {avg: 794, std: 5}, {avg: 1577, std: 8}, {avg: 3138, std: 13}, {avg: 6308, std: 25}}

func poly_small_sqnorm(f *int8, logn uint) uint32 {
	var (
		n  uint64
		u  uint64
		s  uint32
		ng uint32
	)
	n = uint64(1 << logn)
	s = 0
	ng = 0
	for u = 0; u < n; u++ {
		var z int32
		z = int32(*(*int8)(unsafe.Add(unsafe.Pointer(f), u)))
		s += uint32(int32(int(z) * int(z)))
		ng |= s
	}
	return uint32(int32(int(s) | int(uint32(int32(-(int(ng) >> 31))))))
}
func align_fpr(base unsafe.Pointer, data unsafe.Pointer) *fpr {
	var (
		cb *uint8
		cd *uint8
		k  uint64
		km uint64
	)
	cb = (*uint8)(base)
	cd = (*uint8)(data)
	k = uint64(int64(uintptr(unsafe.Pointer(cd)) - uintptr(unsafe.Pointer(cb))))
	km = k % uint64(unsafe.Sizeof(fpr(0)))
	if km != 0 {
		k += uint64((unsafe.Sizeof(fpr(0))) - uintptr(km))
	}
	return (*fpr)(unsafe.Pointer((*uint8)(unsafe.Add(unsafe.Pointer(cb), k))))
}
func align_u32(base unsafe.Pointer, data unsafe.Pointer) *uint32 {
	var (
		cb *uint8
		cd *uint8
		k  uint64
		km uint64
	)
	cb = (*uint8)(base)
	cd = (*uint8)(data)
	k = uint64(int64(uintptr(unsafe.Pointer(cd)) - uintptr(unsafe.Pointer(cb))))
	km = k % uint64(unsafe.Sizeof(uint32(0)))
	if km != 0 {
		k += uint64((unsafe.Sizeof(uint32(0))) - uintptr(km))
	}
	return (*uint32)(unsafe.Pointer((*uint8)(unsafe.Add(unsafe.Pointer(cb), k))))
}
func poly_small_to_fp(x *fpr, f *int8, logn uint) {
	var (
		n uint64
		u uint64
	)
	n = uint64(1 << logn)
	for u = 0; u < n; u++ {
		*(*fpr)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(fpr(0))*uintptr(u))) = fpr_of(int64(*(*int8)(unsafe.Add(unsafe.Pointer(f), u))))
	}
}
func make_fg_step(data *uint32, logn uint, depth uint, in_ntt int, out_ntt int) {
	var (
		n      uint64
		hn     uint64
		u      uint64
		slen   uint64
		tlen   uint64
		fd     *uint32
		gd     *uint32
		fs     *uint32
		gs     *uint32
		gm     *uint32
		igm    *uint32
		t1     *uint32
		primes *small_prime
	)
	n = uint64(1 << logn)
	hn = n >> 1
	slen = MAX_BL_SMALL[depth]
	tlen = MAX_BL_SMALL[depth+1]
	primes = &PRIMES[0]
	fd = data
	gd = (*uint32)(unsafe.Add(unsafe.Pointer(fd), unsafe.Sizeof(uint32(0))*uintptr(hn*tlen)))
	fs = (*uint32)(unsafe.Add(unsafe.Pointer(gd), unsafe.Sizeof(uint32(0))*uintptr(hn*tlen)))
	gs = (*uint32)(unsafe.Add(unsafe.Pointer(fs), unsafe.Sizeof(uint32(0))*uintptr(n*slen)))
	gm = (*uint32)(unsafe.Add(unsafe.Pointer(gs), unsafe.Sizeof(uint32(0))*uintptr(n*slen)))
	igm = (*uint32)(unsafe.Add(unsafe.Pointer(gm), unsafe.Sizeof(uint32(0))*uintptr(n)))
	t1 = (*uint32)(unsafe.Add(unsafe.Pointer(igm), unsafe.Sizeof(uint32(0))*uintptr(n)))
	libc.MemMove(unsafe.Pointer(fs), unsafe.Pointer(data), int(n*2*slen*uint64(unsafe.Sizeof(uint32(0)))))
	for u = 0; u < slen; u++ {
		var (
			p   uint32
			p0i uint32
			R2  uint32
			v   uint64
			x   *uint32
		)
		p = (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*uintptr(u)))).p
		p0i = modp_ninv31(p)
		R2 = modp_R2(p, p0i)
		modp_mkgm2(gm, igm, logn, (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*uintptr(u)))).g, p, p0i)
		for func() *uint32 {
			v = 0
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(fs), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return x
			}()
		}(); v < n; func() *uint32 {
			v++
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(slen)))
				return x
			}()
		}() {
			*(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr(v))) = *x
		}
		if in_ntt == 0 {
			modp_NTT2_ext(t1, 1, gm, logn, p, p0i)
		}
		for func() *uint32 {
			v = 0
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(fd), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return x
			}()
		}(); v < hn; func() *uint32 {
			v++
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(tlen)))
				return x
			}()
		}() {
			var (
				w0 uint32
				w1 uint32
			)
			w0 = *(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+0)))
			w1 = *(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+1)))
			*x = modp_montymul(modp_montymul(w0, w1, p, p0i), R2, p, p0i)
		}
		if in_ntt != 0 {
			modp_iNTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(fs), unsafe.Sizeof(uint32(0))*uintptr(u))), slen, igm, logn, p, p0i)
		}
		for func() *uint32 {
			v = 0
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(gs), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return x
			}()
		}(); v < n; func() *uint32 {
			v++
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(slen)))
				return x
			}()
		}() {
			*(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr(v))) = *x
		}
		if in_ntt == 0 {
			modp_NTT2_ext(t1, 1, gm, logn, p, p0i)
		}
		for func() *uint32 {
			v = 0
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(gd), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return x
			}()
		}(); v < hn; func() *uint32 {
			v++
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(tlen)))
				return x
			}()
		}() {
			var (
				w0 uint32
				w1 uint32
			)
			w0 = *(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+0)))
			w1 = *(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+1)))
			*x = modp_montymul(modp_montymul(w0, w1, p, p0i), R2, p, p0i)
		}
		if in_ntt != 0 {
			modp_iNTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(gs), unsafe.Sizeof(uint32(0))*uintptr(u))), slen, igm, logn, p, p0i)
		}
		if out_ntt == 0 {
			modp_iNTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(fd), unsafe.Sizeof(uint32(0))*uintptr(u))), tlen, igm, logn-1, p, p0i)
			modp_iNTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(gd), unsafe.Sizeof(uint32(0))*uintptr(u))), tlen, igm, logn-1, p, p0i)
		}
	}
	zint_rebuild_CRT(fs, slen, slen, n, primes, 1, gm)
	zint_rebuild_CRT(gs, slen, slen, n, primes, 1, gm)
	for u = slen; u < tlen; u++ {
		var (
			p   uint32
			p0i uint32
			R2  uint32
			Rx  uint32
			v   uint64
			x   *uint32
		)
		p = (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*uintptr(u)))).p
		p0i = modp_ninv31(p)
		R2 = modp_R2(p, p0i)
		Rx = modp_Rx(uint(slen), p, p0i, R2)
		modp_mkgm2(gm, igm, logn, (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*uintptr(u)))).g, p, p0i)
		for func() *uint32 {
			v = 0
			return func() *uint32 {
				x = fs
				return x
			}()
		}(); v < n; func() *uint32 {
			v++
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(slen)))
				return x
			}()
		}() {
			*(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr(v))) = zint_mod_small_signed(x, slen, p, p0i, R2, Rx)
		}
		modp_NTT2_ext(t1, 1, gm, logn, p, p0i)
		for func() *uint32 {
			v = 0
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(fd), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return x
			}()
		}(); v < hn; func() *uint32 {
			v++
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(tlen)))
				return x
			}()
		}() {
			var (
				w0 uint32
				w1 uint32
			)
			w0 = *(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+0)))
			w1 = *(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+1)))
			*x = modp_montymul(modp_montymul(w0, w1, p, p0i), R2, p, p0i)
		}
		for func() *uint32 {
			v = 0
			return func() *uint32 {
				x = gs
				return x
			}()
		}(); v < n; func() *uint32 {
			v++
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(slen)))
				return x
			}()
		}() {
			*(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr(v))) = zint_mod_small_signed(x, slen, p, p0i, R2, Rx)
		}
		modp_NTT2_ext(t1, 1, gm, logn, p, p0i)
		for func() *uint32 {
			v = 0
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(gd), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return x
			}()
		}(); v < hn; func() *uint32 {
			v++
			return func() *uint32 {
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(tlen)))
				return x
			}()
		}() {
			var (
				w0 uint32
				w1 uint32
			)
			w0 = *(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+0)))
			w1 = *(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+1)))
			*x = modp_montymul(modp_montymul(w0, w1, p, p0i), R2, p, p0i)
		}
		if out_ntt == 0 {
			modp_iNTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(fd), unsafe.Sizeof(uint32(0))*uintptr(u))), tlen, igm, logn-1, p, p0i)
			modp_iNTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(gd), unsafe.Sizeof(uint32(0))*uintptr(u))), tlen, igm, logn-1, p, p0i)
		}
	}
}
func make_fg(data *uint32, f *int8, g *int8, logn uint, depth uint, out_ntt int) {
	var (
		n      uint64
		u      uint64
		ft     *uint32
		gt     *uint32
		p0     uint32
		d      uint
		primes *small_prime
	)
	n = uint64(1 << logn)
	ft = data
	gt = (*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(n)))
	primes = &PRIMES[0]
	p0 = (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*0))).p
	for u = 0; u < n; u++ {
		*(*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(f), u))), p0)
		*(*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(g), u))), p0)
	}
	if depth == 0 && out_ntt != 0 {
		var (
			gm  *uint32
			igm *uint32
			p   uint32
			p0i uint32
		)
		p = (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*0))).p
		p0i = modp_ninv31(p)
		gm = (*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(n)))
		igm = (*uint32)(unsafe.Add(unsafe.Pointer(gm), unsafe.Sizeof(uint32(0))*uintptr(1<<logn)))
		modp_mkgm2(gm, igm, logn, (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*0))).g, p, p0i)
		modp_NTT2_ext(ft, 1, gm, logn, p, p0i)
		modp_NTT2_ext(gt, 1, gm, logn, p, p0i)
		return
	}
	if depth == 0 {
		return
	}
	if depth == 1 {
		make_fg_step(data, logn, 0, 0, out_ntt)
		return
	}
	make_fg_step(data, logn, 0, 0, 1)
	for d = 1; d+1 < depth; d++ {
		make_fg_step(data, logn-d, d, 1, 1)
	}
	make_fg_step(data, logn-depth+1, depth-1, 1, out_ntt)
}
func solve_NTRU_deepest(logn_top uint, f *int8, g *int8, tmp *uint32) int {
	var (
		len_   uint64
		Fp     *uint32
		Gp     *uint32
		fp     *uint32
		gp     *uint32
		t1     *uint32
		q      uint32
		primes *small_prime
	)
	len_ = MAX_BL_SMALL[logn_top]
	primes = &PRIMES[0]
	Fp = tmp
	Gp = (*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(len_)))
	fp = (*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(len_)))
	gp = (*uint32)(unsafe.Add(unsafe.Pointer(fp), unsafe.Sizeof(uint32(0))*uintptr(len_)))
	t1 = (*uint32)(unsafe.Add(unsafe.Pointer(gp), unsafe.Sizeof(uint32(0))*uintptr(len_)))
	make_fg(fp, f, g, logn_top, logn_top, 0)
	zint_rebuild_CRT(fp, len_, len_, 2, primes, 0, t1)
	if zint_bezout(Gp, Fp, fp, gp, len_, t1) == 0 {
		return 0
	}
	q = 12289
	if int(zint_mul_small(Fp, len_, q)) != 0 || int(zint_mul_small(Gp, len_, q)) != 0 {
		return 0
	}
	return 1
}
func solve_NTRU_intermediate(logn_top uint, f *int8, g *int8, depth uint, tmp *uint32) int {
	var (
		logn     uint
		n        uint64
		hn       uint64
		slen     uint64
		dlen     uint64
		llen     uint64
		rlen     uint64
		FGlen    uint64
		u        uint64
		Fd       *uint32
		Gd       *uint32
		Ft       *uint32
		Gt       *uint32
		ft       *uint32
		gt       *uint32
		t1       *uint32
		rt1      *fpr
		rt2      *fpr
		rt3      *fpr
		rt4      *fpr
		rt5      *fpr
		scale_fg int
		minbl_fg int
		maxbl_fg int
		maxbl_FG int
		scale_k  int
		x        *uint32
		y        *uint32
		k        *int32
		primes   *small_prime
	)
	logn = logn_top - depth
	n = uint64(1 << logn)
	hn = n >> 1
	slen = MAX_BL_SMALL[depth]
	dlen = MAX_BL_SMALL[depth+1]
	llen = MAX_BL_LARGE[depth]
	primes = &PRIMES[0]
	Fd = tmp
	Gd = (*uint32)(unsafe.Add(unsafe.Pointer(Fd), unsafe.Sizeof(uint32(0))*uintptr(dlen*hn)))
	ft = (*uint32)(unsafe.Add(unsafe.Pointer(Gd), unsafe.Sizeof(uint32(0))*uintptr(dlen*hn)))
	make_fg(ft, f, g, logn_top, depth, 1)
	Ft = tmp
	Gt = (*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(n*llen)))
	t1 = (*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(n*llen)))
	libc.MemMove(unsafe.Pointer(t1), unsafe.Pointer(ft), int(n*2*slen*uint64(unsafe.Sizeof(uint32(0)))))
	ft = t1
	gt = (*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(slen*n)))
	t1 = (*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(slen*n)))
	libc.MemMove(unsafe.Pointer(t1), unsafe.Pointer(Fd), int(hn*2*dlen*uint64(unsafe.Sizeof(uint32(0)))))
	Fd = t1
	Gd = (*uint32)(unsafe.Add(unsafe.Pointer(Fd), unsafe.Sizeof(uint32(0))*uintptr(hn*dlen)))
	for u = 0; u < llen; u++ {
		var (
			p   uint32
			p0i uint32
			R2  uint32
			Rx  uint32
			v   uint64
			xs  *uint32
			ys  *uint32
			xd  *uint32
			yd  *uint32
		)
		p = (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*uintptr(u)))).p
		p0i = modp_ninv31(p)
		R2 = modp_R2(p, p0i)
		Rx = modp_Rx(uint(dlen), p, p0i, R2)
		for func() *uint32 {
			v = 0
			xs = Fd
			ys = Gd
			xd = (*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(u)))
			return func() *uint32 {
				yd = (*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return yd
			}()
		}(); v < hn; func() *uint32 {
			v++
			xs = (*uint32)(unsafe.Add(unsafe.Pointer(xs), unsafe.Sizeof(uint32(0))*uintptr(dlen)))
			ys = (*uint32)(unsafe.Add(unsafe.Pointer(ys), unsafe.Sizeof(uint32(0))*uintptr(dlen)))
			xd = (*uint32)(unsafe.Add(unsafe.Pointer(xd), unsafe.Sizeof(uint32(0))*uintptr(llen)))
			return func() *uint32 {
				yd = (*uint32)(unsafe.Add(unsafe.Pointer(yd), unsafe.Sizeof(uint32(0))*uintptr(llen)))
				return yd
			}()
		}() {
			*xd = zint_mod_small_signed(xs, dlen, p, p0i, R2, Rx)
			*yd = zint_mod_small_signed(ys, dlen, p, p0i, R2, Rx)
		}
	}
	for u = 0; u < llen; u++ {
		var (
			p   uint32
			p0i uint32
			R2  uint32
			gm  *uint32
			igm *uint32
			fx  *uint32
			gx  *uint32
			Fp  *uint32
			Gp  *uint32
			v   uint64
		)
		p = (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*uintptr(u)))).p
		p0i = modp_ninv31(p)
		R2 = modp_R2(p, p0i)
		if u == slen {
			zint_rebuild_CRT(ft, slen, slen, n, primes, 1, t1)
			zint_rebuild_CRT(gt, slen, slen, n, primes, 1, t1)
		}
		gm = t1
		igm = (*uint32)(unsafe.Add(unsafe.Pointer(gm), unsafe.Sizeof(uint32(0))*uintptr(n)))
		fx = (*uint32)(unsafe.Add(unsafe.Pointer(igm), unsafe.Sizeof(uint32(0))*uintptr(n)))
		gx = (*uint32)(unsafe.Add(unsafe.Pointer(fx), unsafe.Sizeof(uint32(0))*uintptr(n)))
		modp_mkgm2(gm, igm, logn, (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*uintptr(u)))).g, p, p0i)
		if u < slen {
			for func() *uint32 {
				v = 0
				x = (*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return func() *uint32 {
					y = (*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(u)))
					return y
				}()
			}(); v < n; func() *uint32 {
				v++
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(slen)))
				return func() *uint32 {
					y = (*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(slen)))
					return y
				}()
			}() {
				*(*uint32)(unsafe.Add(unsafe.Pointer(fx), unsafe.Sizeof(uint32(0))*uintptr(v))) = *x
				*(*uint32)(unsafe.Add(unsafe.Pointer(gx), unsafe.Sizeof(uint32(0))*uintptr(v))) = *y
			}
			modp_iNTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(u))), slen, igm, logn, p, p0i)
			modp_iNTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(u))), slen, igm, logn, p, p0i)
		} else {
			var Rx uint32
			Rx = modp_Rx(uint(slen), p, p0i, R2)
			for func() *uint32 {
				v = 0
				x = ft
				return func() *uint32 {
					y = gt
					return y
				}()
			}(); v < n; func() *uint32 {
				v++
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(slen)))
				return func() *uint32 {
					y = (*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(slen)))
					return y
				}()
			}() {
				*(*uint32)(unsafe.Add(unsafe.Pointer(fx), unsafe.Sizeof(uint32(0))*uintptr(v))) = zint_mod_small_signed(x, slen, p, p0i, R2, Rx)
				*(*uint32)(unsafe.Add(unsafe.Pointer(gx), unsafe.Sizeof(uint32(0))*uintptr(v))) = zint_mod_small_signed(y, slen, p, p0i, R2, Rx)
			}
			modp_NTT2_ext(fx, 1, gm, logn, p, p0i)
			modp_NTT2_ext(gx, 1, gm, logn, p, p0i)
		}
		Fp = (*uint32)(unsafe.Add(unsafe.Pointer(gx), unsafe.Sizeof(uint32(0))*uintptr(n)))
		Gp = (*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(hn)))
		for func() *uint32 {
			v = 0
			x = (*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(u)))
			return func() *uint32 {
				y = (*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return y
			}()
		}(); v < hn; func() *uint32 {
			v++
			x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(llen)))
			return func() *uint32 {
				y = (*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(llen)))
				return y
			}()
		}() {
			*(*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(v))) = *x
			*(*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(v))) = *y
		}
		modp_NTT2_ext(Fp, 1, gm, logn-1, p, p0i)
		modp_NTT2_ext(Gp, 1, gm, logn-1, p, p0i)
		for func() *uint32 {
			v = 0
			x = (*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(u)))
			return func() *uint32 {
				y = (*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return y
			}()
		}(); v < hn; func() *uint32 {
			v++
			x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(llen<<1)))
			return func() *uint32 {
				y = (*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(llen<<1)))
				return y
			}()
		}() {
			var (
				ftA uint32
				ftB uint32
				gtA uint32
				gtB uint32
				mFp uint32
				mGp uint32
			)
			ftA = *(*uint32)(unsafe.Add(unsafe.Pointer(fx), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+0)))
			ftB = *(*uint32)(unsafe.Add(unsafe.Pointer(fx), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+1)))
			gtA = *(*uint32)(unsafe.Add(unsafe.Pointer(gx), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+0)))
			gtB = *(*uint32)(unsafe.Add(unsafe.Pointer(gx), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+1)))
			mFp = modp_montymul(*(*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(v))), R2, p, p0i)
			mGp = modp_montymul(*(*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(v))), R2, p, p0i)
			*(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*0)) = modp_montymul(gtB, mFp, p, p0i)
			*(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(llen))) = modp_montymul(gtA, mFp, p, p0i)
			*(*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*0)) = modp_montymul(ftB, mGp, p, p0i)
			*(*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(llen))) = modp_montymul(ftA, mGp, p, p0i)
		}
		modp_iNTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(u))), llen, igm, logn, p, p0i)
		modp_iNTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(u))), llen, igm, logn, p, p0i)
	}
	zint_rebuild_CRT(Ft, llen, llen, n, primes, 1, t1)
	zint_rebuild_CRT(Gt, llen, llen, n, primes, 1, t1)
	rt3 = align_fpr(unsafe.Pointer(tmp), unsafe.Pointer(t1))
	rt4 = (*fpr)(unsafe.Add(unsafe.Pointer(rt3), unsafe.Sizeof(fpr(0))*uintptr(n)))
	rt5 = (*fpr)(unsafe.Add(unsafe.Pointer(rt4), unsafe.Sizeof(fpr(0))*uintptr(n)))
	rt1 = (*fpr)(unsafe.Add(unsafe.Pointer(rt5), unsafe.Sizeof(fpr(0))*uintptr(n>>1)))
	k = (*int32)(unsafe.Pointer(align_u32(unsafe.Pointer(tmp), unsafe.Pointer(rt1))))
	rt2 = align_fpr(unsafe.Pointer(tmp), unsafe.Pointer((*int32)(unsafe.Add(unsafe.Pointer(k), unsafe.Sizeof(int32(0))*uintptr(n)))))
	if uintptr(unsafe.Pointer(rt2)) < uintptr(unsafe.Pointer((*fpr)(unsafe.Add(unsafe.Pointer(rt1), unsafe.Sizeof(fpr(0))*uintptr(n))))) {
		rt2 = (*fpr)(unsafe.Add(unsafe.Pointer(rt1), unsafe.Sizeof(fpr(0))*uintptr(n)))
	}
	t1 = (*uint32)(unsafe.Add(unsafe.Pointer((*uint32)(unsafe.Pointer(k))), unsafe.Sizeof(uint32(0))*uintptr(n)))
	if slen > 10 {
		rlen = 10
	} else {
		rlen = slen
	}
	poly_big_to_fp(rt3, (*uint32)(unsafe.Add(unsafe.Pointer((*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(slen)))), -int(unsafe.Sizeof(uint32(0))*uintptr(rlen)))), rlen, slen, logn)
	poly_big_to_fp(rt4, (*uint32)(unsafe.Add(unsafe.Pointer((*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(slen)))), -int(unsafe.Sizeof(uint32(0))*uintptr(rlen)))), rlen, slen, logn)
	scale_fg = int(slen-rlen) * 31
	minbl_fg = BITLENGTH[depth].avg - BITLENGTH[depth].std*6
	maxbl_fg = BITLENGTH[depth].avg + BITLENGTH[depth].std*6
	PQCLEAN_FALCON512_CLEAN_FFT(rt3, logn)
	PQCLEAN_FALCON512_CLEAN_FFT(rt4, logn)
	PQCLEAN_FALCON512_CLEAN_poly_invnorm2_fft(rt5, rt3, rt4, logn)
	PQCLEAN_FALCON512_CLEAN_poly_adj_fft(rt3, logn)
	PQCLEAN_FALCON512_CLEAN_poly_adj_fft(rt4, logn)
	FGlen = llen
	maxbl_FG = int(llen) * 31
	scale_k = maxbl_FG - minbl_fg
	for {
		var (
			scale_FG     int
			dc           int
			new_maxbl_FG int
			scl          uint32
			sch          uint32
			pdc          fpr
			pt           fpr
		)
		if FGlen > 10 {
			rlen = 10
		} else {
			rlen = FGlen
		}
		scale_FG = int(FGlen-rlen) * 31
		poly_big_to_fp(rt1, (*uint32)(unsafe.Add(unsafe.Pointer((*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(FGlen)))), -int(unsafe.Sizeof(uint32(0))*uintptr(rlen)))), rlen, llen, logn)
		poly_big_to_fp(rt2, (*uint32)(unsafe.Add(unsafe.Pointer((*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(FGlen)))), -int(unsafe.Sizeof(uint32(0))*uintptr(rlen)))), rlen, llen, logn)
		PQCLEAN_FALCON512_CLEAN_FFT(rt1, logn)
		PQCLEAN_FALCON512_CLEAN_FFT(rt2, logn)
		PQCLEAN_FALCON512_CLEAN_poly_mul_fft(rt1, rt3, logn)
		PQCLEAN_FALCON512_CLEAN_poly_mul_fft(rt2, rt4, logn)
		PQCLEAN_FALCON512_CLEAN_poly_add(rt2, rt1, logn)
		PQCLEAN_FALCON512_CLEAN_poly_mul_autoadj_fft(rt2, rt5, logn)
		PQCLEAN_FALCON512_CLEAN_iFFT(rt2, logn)
		dc = scale_k - scale_FG + scale_fg
		if dc < 0 {
			dc = -dc
			pt = fpr_two
		} else {
			pt = fpr_onehalf
		}
		pdc = fpr_one
		for dc != 0 {
			if (dc & 1) != 0 {
				pdc = PQCLEAN_FALCON512_CLEAN_fpr_mul(pdc, pt)
			}
			dc >>= 1
			pt = fpr_sqr(pt)
		}
		for u = 0; u < n; u++ {
			var xv fpr
			xv = PQCLEAN_FALCON512_CLEAN_fpr_mul(*(*fpr)(unsafe.Add(unsafe.Pointer(rt2), unsafe.Sizeof(fpr(0))*uintptr(u))), pdc)
			if fpr_lt(fpr_mtwo31m1, xv) == 0 || fpr_lt(xv, fpr_ptwo31m1) == 0 {
				return 0
			}
			*(*int32)(unsafe.Add(unsafe.Pointer(k), unsafe.Sizeof(int32(0))*uintptr(u))) = int32(fpr_rint(xv))
		}
		sch = uint32(int32(scale_k / 31))
		scl = uint32(int32(scale_k % 31))
		if depth <= DEPTH_INT_FG {
			poly_sub_scaled_ntt(Ft, FGlen, llen, ft, slen, slen, k, sch, scl, logn, t1)
			poly_sub_scaled_ntt(Gt, FGlen, llen, gt, slen, slen, k, sch, scl, logn, t1)
		} else {
			poly_sub_scaled(Ft, FGlen, llen, ft, slen, slen, k, sch, scl, logn)
			poly_sub_scaled(Gt, FGlen, llen, gt, slen, slen, k, sch, scl, logn)
		}
		new_maxbl_FG = scale_k + maxbl_fg + 10
		if new_maxbl_FG < maxbl_FG {
			maxbl_FG = new_maxbl_FG
			if int(FGlen)*31 >= maxbl_FG+31 {
				FGlen--
			}
		}
		if scale_k <= 0 {
			break
		}
		scale_k -= 25
		if scale_k < 0 {
			scale_k = 0
		}
	}
	if FGlen < slen {
		for u = 0; u < n; func() *uint32 {
			u++
			Ft = (*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(llen)))
			return func() *uint32 {
				Gt = (*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(llen)))
				return Gt
			}()
		}() {
			var (
				v  uint64
				sw uint32
			)
			sw = uint32(int32(int(uint32(int32(-(int(*(*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(FGlen-1)))) >> 30)))) >> 1))
			for v = FGlen; v < slen; v++ {
				*(*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(v))) = sw
			}
			sw = uint32(int32(int(uint32(int32(-(int(*(*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(FGlen-1)))) >> 30)))) >> 1))
			for v = FGlen; v < slen; v++ {
				*(*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(v))) = sw
			}
		}
	}
	for func() *uint32 {
		u = 0
		x = tmp
		return func() *uint32 {
			y = tmp
			return y
		}()
	}(); u < (n << 1); func() *uint32 {
		u++
		x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(slen)))
		return func() *uint32 {
			y = (*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(llen)))
			return y
		}()
	}() {
		libc.MemMove(unsafe.Pointer(x), unsafe.Pointer(y), int(slen*uint64(unsafe.Sizeof(uint32(0)))))
	}
	return 1
}
func solve_NTRU_binary_depth1(logn_top uint, f *int8, g *int8, tmp *uint32) int {
	var (
		depth uint
		logn  uint
		n_top uint64
		n     uint64
		hn    uint64
		slen  uint64
		dlen  uint64
		llen  uint64
		u     uint64
		Fd    *uint32
		Gd    *uint32
		Ft    *uint32
		Gt    *uint32
		ft    *uint32
		gt    *uint32
		t1    *uint32
		rt1   *fpr
		rt2   *fpr
		rt3   *fpr
		rt4   *fpr
		rt5   *fpr
		rt6   *fpr
		x     *uint32
		y     *uint32
	)
	depth = 1
	n_top = uint64(1 << logn_top)
	logn = logn_top - depth
	n = uint64(1 << logn)
	hn = n >> 1
	slen = MAX_BL_SMALL[depth]
	dlen = MAX_BL_SMALL[depth+1]
	llen = MAX_BL_LARGE[depth]
	Fd = tmp
	Gd = (*uint32)(unsafe.Add(unsafe.Pointer(Fd), unsafe.Sizeof(uint32(0))*uintptr(dlen*hn)))
	Ft = (*uint32)(unsafe.Add(unsafe.Pointer(Gd), unsafe.Sizeof(uint32(0))*uintptr(dlen*hn)))
	Gt = (*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(llen*n)))
	for u = 0; u < llen; u++ {
		var (
			p   uint32
			p0i uint32
			R2  uint32
			Rx  uint32
			v   uint64
			xs  *uint32
			ys  *uint32
			xd  *uint32
			yd  *uint32
		)
		p = PRIMES[u].p
		p0i = modp_ninv31(p)
		R2 = modp_R2(p, p0i)
		Rx = modp_Rx(uint(dlen), p, p0i, R2)
		for func() *uint32 {
			v = 0
			xs = Fd
			ys = Gd
			xd = (*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(u)))
			return func() *uint32 {
				yd = (*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return yd
			}()
		}(); v < hn; func() *uint32 {
			v++
			xs = (*uint32)(unsafe.Add(unsafe.Pointer(xs), unsafe.Sizeof(uint32(0))*uintptr(dlen)))
			ys = (*uint32)(unsafe.Add(unsafe.Pointer(ys), unsafe.Sizeof(uint32(0))*uintptr(dlen)))
			xd = (*uint32)(unsafe.Add(unsafe.Pointer(xd), unsafe.Sizeof(uint32(0))*uintptr(llen)))
			return func() *uint32 {
				yd = (*uint32)(unsafe.Add(unsafe.Pointer(yd), unsafe.Sizeof(uint32(0))*uintptr(llen)))
				return yd
			}()
		}() {
			*xd = zint_mod_small_signed(xs, dlen, p, p0i, R2, Rx)
			*yd = zint_mod_small_signed(ys, dlen, p, p0i, R2, Rx)
		}
	}
	libc.MemMove(unsafe.Pointer(tmp), unsafe.Pointer(Ft), int(llen*n*uint64(unsafe.Sizeof(uint32(0)))))
	Ft = tmp
	libc.MemMove(unsafe.Pointer((*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(llen*n)))), unsafe.Pointer(Gt), int(llen*n*uint64(unsafe.Sizeof(uint32(0)))))
	Gt = (*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(llen*n)))
	ft = (*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(llen*n)))
	gt = (*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(slen*n)))
	t1 = (*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(slen*n)))
	for u = 0; u < llen; u++ {
		var (
			p   uint32
			p0i uint32
			R2  uint32
			gm  *uint32
			igm *uint32
			fx  *uint32
			gx  *uint32
			Fp  *uint32
			Gp  *uint32
			e   uint
			v   uint64
		)
		p = PRIMES[u].p
		p0i = modp_ninv31(p)
		R2 = modp_R2(p, p0i)
		gm = t1
		igm = (*uint32)(unsafe.Add(unsafe.Pointer(gm), unsafe.Sizeof(uint32(0))*uintptr(n_top)))
		fx = (*uint32)(unsafe.Add(unsafe.Pointer(igm), unsafe.Sizeof(uint32(0))*uintptr(n)))
		gx = (*uint32)(unsafe.Add(unsafe.Pointer(fx), unsafe.Sizeof(uint32(0))*uintptr(n_top)))
		modp_mkgm2(gm, igm, logn_top, PRIMES[u].g, p, p0i)
		for v = 0; v < n_top; v++ {
			*(*uint32)(unsafe.Add(unsafe.Pointer(fx), unsafe.Sizeof(uint32(0))*uintptr(v))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(f), v))), p)
			*(*uint32)(unsafe.Add(unsafe.Pointer(gx), unsafe.Sizeof(uint32(0))*uintptr(v))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(g), v))), p)
		}
		modp_NTT2_ext(fx, 1, gm, logn_top, p, p0i)
		modp_NTT2_ext(gx, 1, gm, logn_top, p, p0i)
		for e = logn_top; e > logn; e-- {
			modp_poly_rec_res(fx, e, p, p0i, R2)
			modp_poly_rec_res(gx, e, p, p0i, R2)
		}
		if depth > 0 {
			libc.MemMove(unsafe.Pointer((*uint32)(unsafe.Add(unsafe.Pointer(gm), unsafe.Sizeof(uint32(0))*uintptr(n)))), unsafe.Pointer(igm), int(n*uint64(unsafe.Sizeof(uint32(0)))))
			igm = (*uint32)(unsafe.Add(unsafe.Pointer(gm), unsafe.Sizeof(uint32(0))*uintptr(n)))
			libc.MemMove(unsafe.Pointer((*uint32)(unsafe.Add(unsafe.Pointer(igm), unsafe.Sizeof(uint32(0))*uintptr(n)))), unsafe.Pointer(fx), int(n*uint64(unsafe.Sizeof(uint32(0)))))
			fx = (*uint32)(unsafe.Add(unsafe.Pointer(igm), unsafe.Sizeof(uint32(0))*uintptr(n)))
			libc.MemMove(unsafe.Pointer((*uint32)(unsafe.Add(unsafe.Pointer(fx), unsafe.Sizeof(uint32(0))*uintptr(n)))), unsafe.Pointer(gx), int(n*uint64(unsafe.Sizeof(uint32(0)))))
			gx = (*uint32)(unsafe.Add(unsafe.Pointer(fx), unsafe.Sizeof(uint32(0))*uintptr(n)))
		}
		Fp = (*uint32)(unsafe.Add(unsafe.Pointer(gx), unsafe.Sizeof(uint32(0))*uintptr(n)))
		Gp = (*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(hn)))
		for func() *uint32 {
			v = 0
			x = (*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(u)))
			return func() *uint32 {
				y = (*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return y
			}()
		}(); v < hn; func() *uint32 {
			v++
			x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(llen)))
			return func() *uint32 {
				y = (*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(llen)))
				return y
			}()
		}() {
			*(*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(v))) = *x
			*(*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(v))) = *y
		}
		modp_NTT2_ext(Fp, 1, gm, logn-1, p, p0i)
		modp_NTT2_ext(Gp, 1, gm, logn-1, p, p0i)
		for func() *uint32 {
			v = 0
			x = (*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(u)))
			return func() *uint32 {
				y = (*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return y
			}()
		}(); v < hn; func() *uint32 {
			v++
			x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(llen<<1)))
			return func() *uint32 {
				y = (*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(llen<<1)))
				return y
			}()
		}() {
			var (
				ftA uint32
				ftB uint32
				gtA uint32
				gtB uint32
				mFp uint32
				mGp uint32
			)
			ftA = *(*uint32)(unsafe.Add(unsafe.Pointer(fx), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+0)))
			ftB = *(*uint32)(unsafe.Add(unsafe.Pointer(fx), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+1)))
			gtA = *(*uint32)(unsafe.Add(unsafe.Pointer(gx), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+0)))
			gtB = *(*uint32)(unsafe.Add(unsafe.Pointer(gx), unsafe.Sizeof(uint32(0))*uintptr((v<<1)+1)))
			mFp = modp_montymul(*(*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(v))), R2, p, p0i)
			mGp = modp_montymul(*(*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(v))), R2, p, p0i)
			*(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*0)) = modp_montymul(gtB, mFp, p, p0i)
			*(*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(llen))) = modp_montymul(gtA, mFp, p, p0i)
			*(*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*0)) = modp_montymul(ftB, mGp, p, p0i)
			*(*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(llen))) = modp_montymul(ftA, mGp, p, p0i)
		}
		modp_iNTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(u))), llen, igm, logn, p, p0i)
		modp_iNTT2_ext((*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(u))), llen, igm, logn, p, p0i)
		if u < slen {
			modp_iNTT2_ext(fx, 1, igm, logn, p, p0i)
			modp_iNTT2_ext(gx, 1, igm, logn, p, p0i)
			for func() *uint32 {
				v = 0
				x = (*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(u)))
				return func() *uint32 {
					y = (*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(u)))
					return y
				}()
			}(); v < n; func() *uint32 {
				v++
				x = (*uint32)(unsafe.Add(unsafe.Pointer(x), unsafe.Sizeof(uint32(0))*uintptr(slen)))
				return func() *uint32 {
					y = (*uint32)(unsafe.Add(unsafe.Pointer(y), unsafe.Sizeof(uint32(0))*uintptr(slen)))
					return y
				}()
			}() {
				*x = *(*uint32)(unsafe.Add(unsafe.Pointer(fx), unsafe.Sizeof(uint32(0))*uintptr(v)))
				*y = *(*uint32)(unsafe.Add(unsafe.Pointer(gx), unsafe.Sizeof(uint32(0))*uintptr(v)))
			}
		}
	}
	zint_rebuild_CRT(Ft, llen, llen, n<<1, &PRIMES[0], 1, t1)
	zint_rebuild_CRT(ft, slen, slen, n<<1, &PRIMES[0], 1, t1)
	rt1 = align_fpr(unsafe.Pointer(tmp), unsafe.Pointer((*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(slen*n)))))
	rt2 = (*fpr)(unsafe.Add(unsafe.Pointer(rt1), unsafe.Sizeof(fpr(0))*uintptr(n)))
	poly_big_to_fp(rt1, Ft, llen, llen, logn)
	poly_big_to_fp(rt2, Gt, llen, llen, logn)
	libc.MemMove(unsafe.Pointer(tmp), unsafe.Pointer(ft), int(slen*2*n*uint64(unsafe.Sizeof(uint32(0)))))
	ft = tmp
	gt = (*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(slen*n)))
	rt3 = align_fpr(unsafe.Pointer(tmp), unsafe.Pointer((*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(slen*n)))))
	libc.MemMove(unsafe.Pointer(rt3), unsafe.Pointer(rt1), int(n*2*uint64(unsafe.Sizeof(fpr(0)))))
	rt1 = rt3
	rt2 = (*fpr)(unsafe.Add(unsafe.Pointer(rt1), unsafe.Sizeof(fpr(0))*uintptr(n)))
	rt3 = (*fpr)(unsafe.Add(unsafe.Pointer(rt2), unsafe.Sizeof(fpr(0))*uintptr(n)))
	rt4 = (*fpr)(unsafe.Add(unsafe.Pointer(rt3), unsafe.Sizeof(fpr(0))*uintptr(n)))
	poly_big_to_fp(rt3, ft, slen, slen, logn)
	poly_big_to_fp(rt4, gt, slen, slen, logn)
	libc.MemMove(unsafe.Pointer(tmp), unsafe.Pointer(rt1), int(n*4*uint64(unsafe.Sizeof(fpr(0)))))
	rt1 = (*fpr)(unsafe.Pointer(tmp))
	rt2 = (*fpr)(unsafe.Add(unsafe.Pointer(rt1), unsafe.Sizeof(fpr(0))*uintptr(n)))
	rt3 = (*fpr)(unsafe.Add(unsafe.Pointer(rt2), unsafe.Sizeof(fpr(0))*uintptr(n)))
	rt4 = (*fpr)(unsafe.Add(unsafe.Pointer(rt3), unsafe.Sizeof(fpr(0))*uintptr(n)))
	PQCLEAN_FALCON512_CLEAN_FFT(rt1, logn)
	PQCLEAN_FALCON512_CLEAN_FFT(rt2, logn)
	PQCLEAN_FALCON512_CLEAN_FFT(rt3, logn)
	PQCLEAN_FALCON512_CLEAN_FFT(rt4, logn)
	rt5 = (*fpr)(unsafe.Add(unsafe.Pointer(rt4), unsafe.Sizeof(fpr(0))*uintptr(n)))
	rt6 = (*fpr)(unsafe.Add(unsafe.Pointer(rt5), unsafe.Sizeof(fpr(0))*uintptr(n)))
	PQCLEAN_FALCON512_CLEAN_poly_add_muladj_fft(rt5, rt1, rt2, rt3, rt4, logn)
	PQCLEAN_FALCON512_CLEAN_poly_invnorm2_fft(rt6, rt3, rt4, logn)
	PQCLEAN_FALCON512_CLEAN_poly_mul_autoadj_fft(rt5, rt6, logn)
	PQCLEAN_FALCON512_CLEAN_iFFT(rt5, logn)
	for u = 0; u < n; u++ {
		var z fpr
		z = *(*fpr)(unsafe.Add(unsafe.Pointer(rt5), unsafe.Sizeof(fpr(0))*uintptr(u)))
		if fpr_lt(z, fpr_ptwo63m1) == 0 || fpr_lt(fpr_mtwo63m1, z) == 0 {
			return 0
		}
		*(*fpr)(unsafe.Add(unsafe.Pointer(rt5), unsafe.Sizeof(fpr(0))*uintptr(u))) = fpr_of(fpr_rint(z))
	}
	PQCLEAN_FALCON512_CLEAN_FFT(rt5, logn)
	PQCLEAN_FALCON512_CLEAN_poly_mul_fft(rt3, rt5, logn)
	PQCLEAN_FALCON512_CLEAN_poly_mul_fft(rt4, rt5, logn)
	PQCLEAN_FALCON512_CLEAN_poly_sub(rt1, rt3, logn)
	PQCLEAN_FALCON512_CLEAN_poly_sub(rt2, rt4, logn)
	PQCLEAN_FALCON512_CLEAN_iFFT(rt1, logn)
	PQCLEAN_FALCON512_CLEAN_iFFT(rt2, logn)
	Ft = tmp
	Gt = (*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(n)))
	rt3 = align_fpr(unsafe.Pointer(tmp), unsafe.Pointer((*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(n)))))
	libc.MemMove(unsafe.Pointer(rt3), unsafe.Pointer(rt1), int(n*2*uint64(unsafe.Sizeof(fpr(0)))))
	rt1 = rt3
	rt2 = (*fpr)(unsafe.Add(unsafe.Pointer(rt1), unsafe.Sizeof(fpr(0))*uintptr(n)))
	for u = 0; u < n; u++ {
		*(*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(u))) = uint32(int32(fpr_rint(*(*fpr)(unsafe.Add(unsafe.Pointer(rt1), unsafe.Sizeof(fpr(0))*uintptr(u))))))
		*(*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(u))) = uint32(int32(fpr_rint(*(*fpr)(unsafe.Add(unsafe.Pointer(rt2), unsafe.Sizeof(fpr(0))*uintptr(u))))))
	}
	return 1
}
func solve_NTRU_binary_depth0(logn uint, f *int8, g *int8, tmp *uint32) int {
	var (
		n   uint64
		hn  uint64
		u   uint64
		p   uint32
		p0i uint32
		R2  uint32
		Fp  *uint32
		Gp  *uint32
		t1  *uint32
		t2  *uint32
		t3  *uint32
		t4  *uint32
		t5  *uint32
		gm  *uint32
		igm *uint32
		ft  *uint32
		gt  *uint32
		rt2 *fpr
		rt3 *fpr
	)
	n = uint64(1 << logn)
	hn = n >> 1
	p = PRIMES[0].p
	p0i = modp_ninv31(p)
	R2 = modp_R2(p, p0i)
	Fp = tmp
	Gp = (*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(hn)))
	ft = (*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(hn)))
	gt = (*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(n)))
	gm = (*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(n)))
	igm = (*uint32)(unsafe.Add(unsafe.Pointer(gm), unsafe.Sizeof(uint32(0))*uintptr(n)))
	modp_mkgm2(gm, igm, logn, PRIMES[0].g, p, p0i)
	for u = 0; u < hn; u++ {
		*(*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(zint_one_to_plain((*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(u)))), p)
		*(*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(zint_one_to_plain((*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(u)))), p)
	}
	modp_NTT2_ext(Fp, 1, gm, logn-1, p, p0i)
	modp_NTT2_ext(Gp, 1, gm, logn-1, p, p0i)
	for u = 0; u < n; u++ {
		*(*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(f), u))), p)
		*(*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(g), u))), p)
	}
	modp_NTT2_ext(ft, 1, gm, logn, p, p0i)
	modp_NTT2_ext(gt, 1, gm, logn, p, p0i)
	for u = 0; u < n; u += 2 {
		var (
			ftA uint32
			ftB uint32
			gtA uint32
			gtB uint32
			mFp uint32
			mGp uint32
		)
		ftA = *(*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(u+0)))
		ftB = *(*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(u+1)))
		gtA = *(*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(u+0)))
		gtB = *(*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(u+1)))
		mFp = modp_montymul(*(*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(u>>1))), R2, p, p0i)
		mGp = modp_montymul(*(*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(u>>1))), R2, p, p0i)
		*(*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(u+0))) = modp_montymul(gtB, mFp, p, p0i)
		*(*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(u+1))) = modp_montymul(gtA, mFp, p, p0i)
		*(*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(u+0))) = modp_montymul(ftB, mGp, p, p0i)
		*(*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(u+1))) = modp_montymul(ftA, mGp, p, p0i)
	}
	modp_iNTT2_ext(ft, 1, igm, logn, p, p0i)
	modp_iNTT2_ext(gt, 1, igm, logn, p, p0i)
	Gp = (*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(n)))
	t1 = (*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(n)))
	libc.MemMove(unsafe.Pointer(Fp), unsafe.Pointer(ft), int(n*2*uint64(unsafe.Sizeof(uint32(0)))))
	t2 = (*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr(n)))
	t3 = (*uint32)(unsafe.Add(unsafe.Pointer(t2), unsafe.Sizeof(uint32(0))*uintptr(n)))
	t4 = (*uint32)(unsafe.Add(unsafe.Pointer(t3), unsafe.Sizeof(uint32(0))*uintptr(n)))
	t5 = (*uint32)(unsafe.Add(unsafe.Pointer(t4), unsafe.Sizeof(uint32(0))*uintptr(n)))
	modp_mkgm2(t1, t2, logn, PRIMES[0].g, p, p0i)
	modp_NTT2_ext(Fp, 1, t1, logn, p, p0i)
	modp_NTT2_ext(Gp, 1, t1, logn, p, p0i)
	*(*uint32)(unsafe.Add(unsafe.Pointer(t4), unsafe.Sizeof(uint32(0))*0)) = func() uint32 {
		p_ := (*uint32)(unsafe.Add(unsafe.Pointer(t5), unsafe.Sizeof(uint32(0))*0))
		*p_ = modp_set(int32(*f), p)
		return *p_
	}()
	for u = 1; u < n; u++ {
		*(*uint32)(unsafe.Add(unsafe.Pointer(t4), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(f), u))), p)
		*(*uint32)(unsafe.Add(unsafe.Pointer(t5), unsafe.Sizeof(uint32(0))*uintptr(n-u))) = modp_set(int32(-*(*int8)(unsafe.Add(unsafe.Pointer(f), u))), p)
	}
	modp_NTT2_ext(t4, 1, t1, logn, p, p0i)
	modp_NTT2_ext(t5, 1, t1, logn, p, p0i)
	for u = 0; u < n; u++ {
		var w uint32
		w = modp_montymul(*(*uint32)(unsafe.Add(unsafe.Pointer(t5), unsafe.Sizeof(uint32(0))*uintptr(u))), R2, p, p0i)
		*(*uint32)(unsafe.Add(unsafe.Pointer(t2), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_montymul(w, *(*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(u))), p, p0i)
		*(*uint32)(unsafe.Add(unsafe.Pointer(t3), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_montymul(w, *(*uint32)(unsafe.Add(unsafe.Pointer(t4), unsafe.Sizeof(uint32(0))*uintptr(u))), p, p0i)
	}
	*(*uint32)(unsafe.Add(unsafe.Pointer(t4), unsafe.Sizeof(uint32(0))*0)) = func() uint32 {
		p_ := (*uint32)(unsafe.Add(unsafe.Pointer(t5), unsafe.Sizeof(uint32(0))*0))
		*p_ = modp_set(int32(*g), p)
		return *p_
	}()
	for u = 1; u < n; u++ {
		*(*uint32)(unsafe.Add(unsafe.Pointer(t4), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(g), u))), p)
		*(*uint32)(unsafe.Add(unsafe.Pointer(t5), unsafe.Sizeof(uint32(0))*uintptr(n-u))) = modp_set(int32(-*(*int8)(unsafe.Add(unsafe.Pointer(g), u))), p)
	}
	modp_NTT2_ext(t4, 1, t1, logn, p, p0i)
	modp_NTT2_ext(t5, 1, t1, logn, p, p0i)
	for u = 0; u < n; u++ {
		var w uint32
		w = modp_montymul(*(*uint32)(unsafe.Add(unsafe.Pointer(t5), unsafe.Sizeof(uint32(0))*uintptr(u))), R2, p, p0i)
		*(*uint32)(unsafe.Add(unsafe.Pointer(t2), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_add(*(*uint32)(unsafe.Add(unsafe.Pointer(t2), unsafe.Sizeof(uint32(0))*uintptr(u))), modp_montymul(w, *(*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(u))), p, p0i), p)
		*(*uint32)(unsafe.Add(unsafe.Pointer(t3), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_add(*(*uint32)(unsafe.Add(unsafe.Pointer(t3), unsafe.Sizeof(uint32(0))*uintptr(u))), modp_montymul(w, *(*uint32)(unsafe.Add(unsafe.Pointer(t4), unsafe.Sizeof(uint32(0))*uintptr(u))), p, p0i), p)
	}
	modp_mkgm2(t1, t4, logn, PRIMES[0].g, p, p0i)
	modp_iNTT2_ext(t2, 1, t4, logn, p, p0i)
	modp_iNTT2_ext(t3, 1, t4, logn, p, p0i)
	for u = 0; u < n; u++ {
		*(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr(u))) = uint32(modp_norm(*(*uint32)(unsafe.Add(unsafe.Pointer(t2), unsafe.Sizeof(uint32(0))*uintptr(u))), p))
		*(*uint32)(unsafe.Add(unsafe.Pointer(t2), unsafe.Sizeof(uint32(0))*uintptr(u))) = uint32(modp_norm(*(*uint32)(unsafe.Add(unsafe.Pointer(t3), unsafe.Sizeof(uint32(0))*uintptr(u))), p))
	}
	rt3 = align_fpr(unsafe.Pointer(tmp), unsafe.Pointer(t3))
	for u = 0; u < n; u++ {
		*(*fpr)(unsafe.Add(unsafe.Pointer(rt3), unsafe.Sizeof(fpr(0))*uintptr(u))) = fpr_of(int64(*(*int32)(unsafe.Add(unsafe.Pointer((*int32)(unsafe.Pointer(t2))), unsafe.Sizeof(int32(0))*uintptr(u)))))
	}
	PQCLEAN_FALCON512_CLEAN_FFT(rt3, logn)
	rt2 = align_fpr(unsafe.Pointer(tmp), unsafe.Pointer(t2))
	libc.MemMove(unsafe.Pointer(rt2), unsafe.Pointer(rt3), int(hn*uint64(unsafe.Sizeof(fpr(0)))))
	rt3 = (*fpr)(unsafe.Add(unsafe.Pointer(rt2), unsafe.Sizeof(fpr(0))*uintptr(hn)))
	for u = 0; u < n; u++ {
		*(*fpr)(unsafe.Add(unsafe.Pointer(rt3), unsafe.Sizeof(fpr(0))*uintptr(u))) = fpr_of(int64(*(*int32)(unsafe.Add(unsafe.Pointer((*int32)(unsafe.Pointer(t1))), unsafe.Sizeof(int32(0))*uintptr(u)))))
	}
	PQCLEAN_FALCON512_CLEAN_FFT(rt3, logn)
	PQCLEAN_FALCON512_CLEAN_poly_div_autoadj_fft(rt3, rt2, logn)
	PQCLEAN_FALCON512_CLEAN_iFFT(rt3, logn)
	for u = 0; u < n; u++ {
		*(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(int32(fpr_rint(*(*fpr)(unsafe.Add(unsafe.Pointer(rt3), unsafe.Sizeof(fpr(0))*uintptr(u))))), p)
	}
	t2 = (*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr(n)))
	t3 = (*uint32)(unsafe.Add(unsafe.Pointer(t2), unsafe.Sizeof(uint32(0))*uintptr(n)))
	t4 = (*uint32)(unsafe.Add(unsafe.Pointer(t3), unsafe.Sizeof(uint32(0))*uintptr(n)))
	t5 = (*uint32)(unsafe.Add(unsafe.Pointer(t4), unsafe.Sizeof(uint32(0))*uintptr(n)))
	modp_mkgm2(t2, t3, logn, PRIMES[0].g, p, p0i)
	for u = 0; u < n; u++ {
		*(*uint32)(unsafe.Add(unsafe.Pointer(t4), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(f), u))), p)
		*(*uint32)(unsafe.Add(unsafe.Pointer(t5), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(g), u))), p)
	}
	modp_NTT2_ext(t1, 1, t2, logn, p, p0i)
	modp_NTT2_ext(t4, 1, t2, logn, p, p0i)
	modp_NTT2_ext(t5, 1, t2, logn, p, p0i)
	for u = 0; u < n; u++ {
		var kw uint32
		kw = modp_montymul(*(*uint32)(unsafe.Add(unsafe.Pointer(t1), unsafe.Sizeof(uint32(0))*uintptr(u))), R2, p, p0i)
		*(*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_sub(*(*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(u))), modp_montymul(kw, *(*uint32)(unsafe.Add(unsafe.Pointer(t4), unsafe.Sizeof(uint32(0))*uintptr(u))), p, p0i), p)
		*(*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_sub(*(*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(u))), modp_montymul(kw, *(*uint32)(unsafe.Add(unsafe.Pointer(t5), unsafe.Sizeof(uint32(0))*uintptr(u))), p, p0i), p)
	}
	modp_iNTT2_ext(Fp, 1, t3, logn, p, p0i)
	modp_iNTT2_ext(Gp, 1, t3, logn, p, p0i)
	for u = 0; u < n; u++ {
		*(*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(u))) = uint32(modp_norm(*(*uint32)(unsafe.Add(unsafe.Pointer(Fp), unsafe.Sizeof(uint32(0))*uintptr(u))), p))
		*(*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(u))) = uint32(modp_norm(*(*uint32)(unsafe.Add(unsafe.Pointer(Gp), unsafe.Sizeof(uint32(0))*uintptr(u))), p))
	}
	return 1
}
func solve_NTRU(logn uint, F *int8, G *int8, f *int8, g *int8, lim int, tmp *uint32) int {
	var (
		n      uint64
		u      uint64
		ft     *uint32
		gt     *uint32
		Ft     *uint32
		Gt     *uint32
		gm     *uint32
		p      uint32
		p0i    uint32
		r      uint32
		primes *small_prime
	)
	n = uint64(1 << logn)
	if solve_NTRU_deepest(logn, f, g, tmp) == 0 {
		return 0
	}
	if logn <= 2 {
		var depth uint
		depth = logn
		for func() uint {
			p_ := &depth
			x := *p_
			*p_--
			return x
		}() > 0 {
			if solve_NTRU_intermediate(logn, f, g, depth, tmp) == 0 {
				return 0
			}
		}
	} else {
		var depth uint
		depth = logn
		for func() uint {
			p_ := &depth
			x := *p_
			*p_--
			return x
		}() > 2 {
			if solve_NTRU_intermediate(logn, f, g, depth, tmp) == 0 {
				return 0
			}
		}
		if solve_NTRU_binary_depth1(logn, f, g, tmp) == 0 {
			return 0
		}
		if solve_NTRU_binary_depth0(logn, f, g, tmp) == 0 {
			return 0
		}
	}
	if G == nil {
		G = (*int8)(unsafe.Pointer((*uint32)(unsafe.Add(unsafe.Pointer(tmp), unsafe.Sizeof(uint32(0))*uintptr(n*2)))))
	}
	if poly_big_to_small(F, tmp, lim, logn) == 0 || poly_big_to_small(G, (*uint32)(unsafe.Add(unsafe.Pointer(tmp), unsafe.Sizeof(uint32(0))*uintptr(n))), lim, logn) == 0 {
		return 0
	}
	Gt = tmp
	ft = (*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(n)))
	gt = (*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(n)))
	Ft = (*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(n)))
	gm = (*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(n)))
	primes = &PRIMES[0]
	p = (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*0))).p
	p0i = modp_ninv31(p)
	modp_mkgm2(gm, tmp, logn, (*(*small_prime)(unsafe.Add(unsafe.Pointer(primes), unsafe.Sizeof(small_prime{})*0))).g, p, p0i)
	for u = 0; u < n; u++ {
		*(*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(G), u))), p)
	}
	for u = 0; u < n; u++ {
		*(*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(f), u))), p)
		*(*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(g), u))), p)
		*(*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(u))) = modp_set(int32(*(*int8)(unsafe.Add(unsafe.Pointer(F), u))), p)
	}
	modp_NTT2_ext(ft, 1, gm, logn, p, p0i)
	modp_NTT2_ext(gt, 1, gm, logn, p, p0i)
	modp_NTT2_ext(Ft, 1, gm, logn, p, p0i)
	modp_NTT2_ext(Gt, 1, gm, logn, p, p0i)
	r = modp_montymul(12289, 1, p, p0i)
	for u = 0; u < n; u++ {
		var z uint32
		z = modp_sub(modp_montymul(*(*uint32)(unsafe.Add(unsafe.Pointer(ft), unsafe.Sizeof(uint32(0))*uintptr(u))), *(*uint32)(unsafe.Add(unsafe.Pointer(Gt), unsafe.Sizeof(uint32(0))*uintptr(u))), p, p0i), modp_montymul(*(*uint32)(unsafe.Add(unsafe.Pointer(gt), unsafe.Sizeof(uint32(0))*uintptr(u))), *(*uint32)(unsafe.Add(unsafe.Pointer(Ft), unsafe.Sizeof(uint32(0))*uintptr(u))), p, p0i), p)
		if int(z) != int(r) {
			return 0
		}
	}
	return 1
}
func poly_small_mkgauss(rng *shake256incctx, f *int8, logn uint) {
	var (
		n    uint64
		u    uint64
		mod2 uint
	)
	n = uint64(1 << logn)
	mod2 = 0
	for u = 0; u < n; u++ {
		var s int
	restart:
		s = mkgauss(rng, logn)
		if s < -127 || s > 127 {
			goto restart
		}
		if u == n-1 {
			if (mod2 ^ uint(s&1)) == 0 {
				goto restart
			}
		} else {
			mod2 ^= uint(s & 1)
		}
		*(*int8)(unsafe.Add(unsafe.Pointer(f), u)) = int8(s)
	}
}
func PQCLEAN_FALCON512_CLEAN_keygen(rng *shake256incctx, f *int8, g *int8, F *int8, G *int8, h *uint16, logn uint, tmp *uint8) {
	var (
		n    uint64
		u    uint64
		h2   *uint16
		tmp2 *uint16
		rc   *shake256incctx
	)
	n = uint64(1 << logn)
	rc = rng
	for {
		var (
			rt1   *fpr
			rt2   *fpr
			rt3   *fpr
			bnorm fpr
			normf uint32
			normg uint32
			norm  uint32
			lim   int
		)
		poly_small_mkgauss(rc, f, logn)
		poly_small_mkgauss(rc, g, logn)
		lim = 1 << (int(PQCLEAN_FALCON512_CLEAN_max_fg_bits[logn]) - 1)
		for u = 0; u < n; u++ {
			if int(*(*int8)(unsafe.Add(unsafe.Pointer(f), u))) >= lim || int(*(*int8)(unsafe.Add(unsafe.Pointer(f), u))) <= -lim || int(*(*int8)(unsafe.Add(unsafe.Pointer(g), u))) >= lim || int(*(*int8)(unsafe.Add(unsafe.Pointer(g), u))) <= -lim {
				lim = -1
				break
			}
		}
		if lim < 0 {
			continue
		}
		normf = poly_small_sqnorm(f, logn)
		normg = poly_small_sqnorm(g, logn)
		norm = uint32(int32((int(normf) + int(normg)) | int(uint32(int32(-((int(normf) | int(normg)) >> 31))))))
		if int(norm) >= 16823 {
			continue
		}
		rt1 = (*fpr)(unsafe.Pointer(tmp))
		rt2 = (*fpr)(unsafe.Add(unsafe.Pointer(rt1), unsafe.Sizeof(fpr(0))*uintptr(n)))
		rt3 = (*fpr)(unsafe.Add(unsafe.Pointer(rt2), unsafe.Sizeof(fpr(0))*uintptr(n)))
		poly_small_to_fp(rt1, f, logn)
		poly_small_to_fp(rt2, g, logn)
		PQCLEAN_FALCON512_CLEAN_FFT(rt1, logn)
		PQCLEAN_FALCON512_CLEAN_FFT(rt2, logn)
		PQCLEAN_FALCON512_CLEAN_poly_invnorm2_fft(rt3, rt1, rt2, logn)
		PQCLEAN_FALCON512_CLEAN_poly_adj_fft(rt1, logn)
		PQCLEAN_FALCON512_CLEAN_poly_adj_fft(rt2, logn)
		PQCLEAN_FALCON512_CLEAN_poly_mulconst(rt1, fpr_q, logn)
		PQCLEAN_FALCON512_CLEAN_poly_mulconst(rt2, fpr_q, logn)
		PQCLEAN_FALCON512_CLEAN_poly_mul_autoadj_fft(rt1, rt3, logn)
		PQCLEAN_FALCON512_CLEAN_poly_mul_autoadj_fft(rt2, rt3, logn)
		PQCLEAN_FALCON512_CLEAN_iFFT(rt1, logn)
		PQCLEAN_FALCON512_CLEAN_iFFT(rt2, logn)
		bnorm = fpr_zero
		for u = 0; u < n; u++ {
			bnorm = PQCLEAN_FALCON512_CLEAN_fpr_add(bnorm, fpr_sqr(*(*fpr)(unsafe.Add(unsafe.Pointer(rt1), unsafe.Sizeof(fpr(0))*uintptr(u)))))
			bnorm = PQCLEAN_FALCON512_CLEAN_fpr_add(bnorm, fpr_sqr(*(*fpr)(unsafe.Add(unsafe.Pointer(rt2), unsafe.Sizeof(fpr(0))*uintptr(u)))))
		}
		if fpr_lt(bnorm, fpr_bnorm_max) == 0 {
			continue
		}
		if h == nil {
			h2 = (*uint16)(unsafe.Pointer(tmp))
			tmp2 = (*uint16)(unsafe.Add(unsafe.Pointer(h2), unsafe.Sizeof(uint16(0))*uintptr(n)))
		} else {
			h2 = h
			tmp2 = (*uint16)(unsafe.Pointer(tmp))
		}
		if PQCLEAN_FALCON512_CLEAN_compute_public(h2, f, g, logn, (*uint8)(unsafe.Pointer(tmp2))) == 0 {
			continue
		}
		lim = (1 << (int(PQCLEAN_FALCON512_CLEAN_max_FG_bits[logn]) - 1)) - 1
		if solve_NTRU(logn, F, G, f, g, lim, (*uint32)(unsafe.Pointer(tmp))) == 0 {
			continue
		}
		break
	}
}
